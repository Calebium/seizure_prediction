{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os\n",
    "import scipy.io as spio\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import re, math\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint as pp\n",
    "from operator import itemgetter\n",
    "\n",
    "import libUtils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG segment state definition and associate functions\n",
    "\n",
    "# Dictionary that defines state keys and values (tuple that contains\n",
    "# the segment label and segment type)\n",
    "dctSegStates = {\n",
    "  'interictal': ('interictal', 0),\n",
    "  'preictal': ('preictal', 1),\n",
    "  'ictal': ('ictal', 2)\n",
    "}\n",
    "\n",
    "# Return the segmentation label given the segmentation type\n",
    "def fnGetSegLabel(argSegType):\n",
    "    lstSegValues = list(dctSegStates.values())  # Get the dictionary values as a list of tuples\n",
    "    dctSegValues = dict(lstSegValues)  # Create a dictionary from a list of tuples\n",
    "    \n",
    "    # Create an inverted dictionary from dctSegValues{}\n",
    "    dctInvertedSegValues = {intValue: strKey for strKey, intValue in dctSegValues.items()}\n",
    "    \n",
    "    return dctInvertedSegValues[argSegType]\n",
    "\n",
    "# Return the segmentation type given the segmentation label\n",
    "def fnGetSegType(argSegLabel):\n",
    "    lstSegValues = list(dctSegStates.values())  # Get the dictionary values as a list of tuples\n",
    "    dctSegValues = dict(lstSegValues)  # Create a dictionary from a list of tuples\n",
    "    \n",
    "    return dctSegValues[argSegLabel]\n",
    "\n",
    "def fnIsSegState(argSegState, argSegType, argDebug = False):\n",
    "    if (argSegState in dctSegStates):\n",
    "        tupSegState = dctSegStates[argSegState]\n",
    "        \n",
    "        if (argDebug):\n",
    "            print('argSegState = {}, argSegType = {}'.format(dctSegStates[argSegState], argSegType))\n",
    "            \n",
    "        if (tupSegState[1] == argSegType):\n",
    "            blnResult = True\n",
    "        else:\n",
    "            blnResult = False\n",
    "    else:\n",
    "        raise Exception('Unknown argSegState ({})'.format(argSegState))\n",
    "        \n",
    "    return blnResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data set name and training set name for each training based\n",
    "# on the CSV file that specifies which EEG segment to use for training\n",
    "\n",
    "# For example: if the .csv file is called, .../CHB-MIT/chb01.csv, we\n",
    "# will extract CHB-MIT as the data set name and chb01 as the CSV name\n",
    "\n",
    "def fnGetDataSetInfo(argCSVPath, argDebug = False):\n",
    "    strParentPath, strFilename = os.path.split(argCSVPath)\n",
    "    \n",
    "    strDataSetName = os.path.basename(strParentPath)\n",
    "    strCSVName, strFileExt = os.path.splitext(strFilename)\n",
    "    \n",
    "    return strDataSetName, strCSVName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file that specifies which EEG segment(s) to use for training\n",
    "\n",
    "# The file is expected to be comma-delimited. The first row is assumed\n",
    "# to be the header, containing a list of column names for the different\n",
    "# CSV fields (the first field is the full path filename of the EEG\n",
    "# segment)\n",
    "\n",
    "# Each remaining row will contain, in the first field, the full path of\n",
    "# the EEG segment\n",
    "\n",
    "# Comment lines (starting with #) and blank lines are allowed, and will\n",
    "# be ignored\n",
    "\n",
    "# TODO: Add an optional argFileExt filter to allow the filtering of file\n",
    "#       type. If none is specified, then no filtering is applied\n",
    "\n",
    "def fnReadDataFileListCSV(argCSVPath, argInfo = True, argDebug = False):\n",
    "    print('Reading data from CSV file at {}'.format(argCSVPath))\n",
    "    print()\n",
    "    \n",
    "    # Get the list of files from the CSV file. The files are not necessarily\n",
    "    # ordered in any specific order\n",
    "    lstMatchingFiles = []\n",
    "    \n",
    "    # Loop through each row in the CSV file\n",
    "    with open(argCSVPath) as objCSVFile:\n",
    "        objCSVReader = csv.reader(objCSVFile, delimiter = ',')\n",
    "        intRow = 0\n",
    "\n",
    "        for lstRow in objCSVReader:  # Read in the row from file\n",
    "            # Skip the first row of column names\n",
    "            if (intRow == 0):\n",
    "                if (argInfo): print('Skipping the first row. Column names are: [{}]'.format(', '.join(lstRow)))\n",
    "            else:\n",
    "                if (argDebug): print('lstRow = [{}] (len(lstRow) = {}) (type(lstRow) = {})'.format(lstRow, len(lstRow), type(lstRow)))\n",
    "                \n",
    "                # Skip empty rows, which are lists with len() = 0\n",
    "                if (len(lstRow) > 0):\n",
    "                    strFullFilename = lstRow[0]  # Read in the first list item from lstRow[]\n",
    "\n",
    "                    # Skip any rows that are comments (starting with a #)\n",
    "                    if not(re.match(r'^#', strFullFilename, re.I)):  # r'' means raw string\n",
    "                        lstMatchingFiles.append(strFullFilename)  # Add the filename to the list of machine files\n",
    "                        if (argInfo): print('  {}'.format(strFullFilename))\n",
    "\n",
    "            intRow += 1\n",
    "            \n",
    "    if (argInfo or argDebug): print()\n",
    "    \n",
    "    return sorted(lstMatchingFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one or more EEG segments from the Kaggle prediction data set\n",
    "# from files (.mat) based on which files are specified in argCSVPath\n",
    "\n",
    "# The units of argResamplingFreq is in Hz and argSubSeqDuration is in\n",
    "# seconds\n",
    "\n",
    "'''\n",
    "Within the .mat data structure:\n",
    "\n",
    "data:               a matrix of EEG sample values arranged row x column as electrode x time\n",
    "data_length_sec:    the time duration of each data row\n",
    "sampling_frequency: the number of data samples representing 1 second of EEG data\n",
    "channels:           a list of electrode names corresponding to the rows in the data field\n",
    "sequence:           the index of the data segment within the one hour series of clips. For example, \n",
    "                    preictal_segment_6.mat has a sequence number of 6, and represents the iEEG data \n",
    "                    from 50 to 60 minutes into the preictal data\n",
    "'''\n",
    "\n",
    "def fnReadKagglePredMatFiles(argCSVPath, argResamplingFreq = -1, argSubSeqDuration = -1, argDebug = False):\n",
    "    lstMatchingFiles = fnReadDataFileListCSV(argCSVPath)\n",
    "    \n",
    "    intNumMatchingFiles = len(lstMatchingFiles)  # Number of matching files\n",
    "    if (argDebug): print('intNumMatchingFiles = {}'.format(intNumMatchingFiles))\n",
    "        \n",
    "    if (argDebug): print()\n",
    "    \n",
    "    intNumProcessedFiles = 0\n",
    "    intAllDataIdx        = 0\n",
    "    \n",
    "    # Import the first .mat file to a Python dictionary to get the shape\n",
    "    # of the data array\n",
    "    matSegment = spio.loadmat(lstMatchingFiles[0])\n",
    "    strSegLabel = sorted(matSegment.keys())[3]\n",
    "    arrData = matSegment[strSegLabel]['data'].item()\n",
    "    if (argDebug): print('arrData.shape = {} ({})'.format(arrData.shape, type(arrData[0][0])))\n",
    "    if (argDebug): print('First matching file = {}'.format(lstMatchingFiles[0]))\n",
    "    \n",
    "    # Get the original segment duration and sampling frequency from the raw data\n",
    "    intSegDuration = matSegment[strSegLabel]['data_length_sec'].item().item()  # TODO: Segment duration could be a float\n",
    "    print('intSegDuration = {}s'.format(intSegDuration))\n",
    "    intSamplingFreq = matSegment[strSegLabel]['sampling_frequency'].item().item()  # TODO: Sampling frequency could be a float\n",
    "    print('intSamplingFreq = {}Hz'.format(intSamplingFreq))\n",
    "    \n",
    "    # Initialize data structures to store data for the entire data set\n",
    "    lstAllSegLabels = []      # List of segment labels\n",
    "    lstAllSegTypes = []       # List of segment types (preictal = 1 or interictal = 2)\n",
    "    \n",
    "    # Use * to unpack the shape tuple and create arrAllData[] using the same dtype as arrData[]\n",
    "    # Resulting shape of data = [feature/channel size x sequence length x batch/segment size]\n",
    "    #arrAllData = np.zeros((*arrData.shape, intNumMatchingFiles), dtype = type(arrData[0][0]))\n",
    "    \n",
    "    # Get the number of features/channels (rows) and time points (cols)\n",
    "    # from the original segment stored in arrData[]\n",
    "    intNumChannels, intNumTimePts = arrData.shape\n",
    "    \n",
    "    # TODO: Double check that intNumTimePts = intSegDuration * intSamplingFreq?\n",
    "    \n",
    "    # If argResamplingFreq = -1 (defautl) or argResamplingFreq > intSamplingFreq,\n",
    "    # use the original sampling frequency (upsampling is not allowed for now)\n",
    "    if ((argResamplingFreq == -1) or (argResamplingFreq > intSamplingFreq)):\n",
    "        argResamplingFreq = intSamplingFreq\n",
    "    print('argResamplingFreq = {}Hz'.format(argResamplingFreq))\n",
    "    \n",
    "    # Calculate the number of time points in each segment after the resampling\n",
    "    intResampledTimePts = round((argResamplingFreq / intSamplingFreq) * intNumTimePts)\n",
    "    print('intResampledTimePts = {}'.format(intResampledTimePts))\n",
    "    \n",
    "    # If argSubSeqDuration = -1 (default) or argSubSeqDuration > intSegDuration,\n",
    "    # default back to the original segment duration\n",
    "    if ((argSubSeqDuration == -1) or (argSubSeqDuration > intSegDuration)):\n",
    "        argSubSeqDuration = intSegDuration  # Do not break segment into subsequences\n",
    "    print('argSubSeqDuration = {}s'.format(argSubSeqDuration))\n",
    "        \n",
    "    # Calculate the number of time points in each segment after splitting up the segment\n",
    "    # into shorter sequences\n",
    "    intSubSeqTimePts = round((argSubSeqDuration / intSegDuration) * intResampledTimePts)\n",
    "    print('intSubSeqTimePts = {}'.format(intSubSeqTimePts))\n",
    "    \n",
    "    # The default value for argSubSeqTimePts is -1, which is the number of time\n",
    "    # points in the original segment, without breaking it up into sebsequences\n",
    "    #if ((argSubSeqTimePts == -1) or (argSubSeqTimePts > intNumTimePts)):\n",
    "    #    argSubSeqTimePts = intNumTimePts  # Do not break segment into subsequences\n",
    "    \n",
    "    # ***TODO: For now, if the number of subsequence time points specified results\n",
    "    #          in the last subsequence not being completely filled up, we default\n",
    "    #          back to not breaking up the segment into subsequences. We can think\n",
    "    #          about how to deal with the last unfilled subsequence later if we do\n",
    "    #          not like this policy\n",
    "    if (intResampledTimePts % intSubSeqTimePts > 0):\n",
    "        intSubSeqTimePts = intResampledTimePts  # Do not break segment into subsequences\n",
    "        \n",
    "        print('WARNING: Time points cannot be divided into complete subsequences')\n",
    "        print('  Resetting intSubSeqTimePts to {}'.format(intSubSeqTimePts))\n",
    "        \n",
    "    # Analyze the number of subsequences to break down from the main segment, and\n",
    "    # whether the time points can be equally divided among all the subsequences\n",
    "    intNumSubSeqs = math.ceil(intResampledTimePts / intSubSeqTimePts)  # Total number of subsequences required\n",
    "    intNumFullSubSeqs = intResampledTimePts // intSubSeqTimePts        # Number of completely filled subsequences\n",
    "    intNumOrphanTimePts = intResampledTimePts % intSubSeqTimePts       # Number of orphan time points\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if (intNumSubSeqs > 1):\n",
    "        print('Splitting each segment into {} subsequences based on intSubSeqTimePts = {}'.format(intNumSubSeqs, intSubSeqTimePts))\n",
    "        print()\n",
    "    \n",
    "    if (argDebug):\n",
    "        print('intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts = {} / {} / {} ({:.2f}%)'.format(intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts, intNumOrphanTimePts/intSubSeqTimePts))\n",
    "        print()\n",
    "    \n",
    "    # Create an array to hold all data segments, taking into account that we may\n",
    "    # have subsequences and multiple data files\n",
    "    \n",
    "    # NOTE: Depending on the max and min values in arrData[] for a particular segment,\n",
    "    #       type(arrData[0][0]) could be int16, int32, or int64. Therefore, it is not\n",
    "    #       a good idea to create arrAllData[] based on the first arrData[] read in.\n",
    "    #       It may be safer to hardcode arrAllData[] to be of type int64\n",
    "    intTotalBatchSize = intNumMatchingFiles * intNumSubSeqs  # Total number of sequences\n",
    "    #arrAllData = np.zeros((intNumChannels, intSubSeqTimePts, intTotalBatchSize), dtype = type(arrData[0][0]))\n",
    "    arrAllData = np.zeros((intNumChannels, intSubSeqTimePts, intTotalBatchSize), dtype = np.int64)  # TODO: Signal values could be a float\n",
    "    if (argDebug): print('arrAllData.shape = {} ({})'.format(arrAllData.shape, type(arrAllData[0][0][0])))\n",
    "    \n",
    "    lstAllSegDurations = []   # List of segment durations (in seconds)\n",
    "    lstAllSamplingFreqs = []  # List of sampling frequencies (in Hz)\n",
    "    lstAllChannels = []       # List of lists (of channel names)\n",
    "    lstAllSequences = []      # List of sequence indices\n",
    "    lstAllSubSequences = []   # List of subsequence indices (if one sequence is broken up into subsequences)\n",
    "    \n",
    "    if (argDebug): print()\n",
    "    \n",
    "    lstBaseFilenames = []\n",
    "    \n",
    "    # Loop through each file in the target directory                                                \n",
    "    for strFullFilename in lstMatchingFiles:\n",
    "        # Process only .mat files\n",
    "        if strFullFilename.endswith('.mat'):\n",
    "            print('Processing {}...'.format(strFullFilename))\n",
    "            \n",
    "            # Extract the filename from the full path\n",
    "            strPath, strFilename = os.path.split(strFullFilename)\n",
    "            lstBaseFilenames.append(strFilename)\n",
    "            \n",
    "            # Import .mat file to a Python dictionary\n",
    "            matSegment = spio.loadmat(strFullFilename)\n",
    "            \n",
    "            # The list of dictionary keys always contain ['__globals__',\n",
    "            # '__header__', '__version__', 'segment_label'], so I assume\n",
    "            # the 4th item contains the segment label after sorting\n",
    "            strSegLabel = sorted(matSegment.keys())[3]\n",
    "            if (argDebug): print('  strSegLabel = {}'.format(strSegLabel))\n",
    "            \n",
    "            # Classes: interictal = 0, preictal = 1\n",
    "            if (re.match(r'interictal', strSegLabel, re.I)):  # r'' means raw string\n",
    "                intSegType = '0'  # Interictal state\n",
    "            elif (re.match(r'preictal', strSegLabel, re.I)):\n",
    "                intSegType = '1'  # Preictal state\n",
    "            else:\n",
    "                intSegType = '-1'  # Unknown segment type\n",
    "            \n",
    "            # matSegment[strSegLabel] is a structured numpy array with\n",
    "            # the data types 'data', 'data_length_sec', 'sampling_frequency',\n",
    "            # 'channels', and 'sequence' (not for test segments)\n",
    "            arrData = matSegment[strSegLabel]['data'].item()\n",
    "            if (argDebug): print('  arrData.shape = {} ({})'.format(arrData.shape, type(arrData[0][0])))\n",
    "            #if (argDebug): print(arrData[0:2, 0:10])\n",
    "            \n",
    "            arrDataMax  = np.max(arrData, axis = 1)\n",
    "            arrDataMin  = np.min(arrData, axis = 1)\n",
    "            arrDataMean = np.mean(arrData, axis = 1)\n",
    "            \n",
    "            intSegDuration = matSegment[strSegLabel]['data_length_sec'].item().item()\n",
    "            if (argDebug): print('  intSegDuration = {}s'.format(intSegDuration))\n",
    "            \n",
    "            intSamplingFreq = matSegment[strSegLabel]['sampling_frequency'].item().item()\n",
    "            if (argDebug): print('  intSamplingFreq = {}Hz'.format(intSamplingFreq))\n",
    "            \n",
    "            lstChannels = []\n",
    "            arrChannels = np.squeeze(matSegment[strSegLabel]['channels'].item())\n",
    "            for arrChannel in arrChannels:\n",
    "                lstChannels.append(arrChannel.item())\n",
    "            if (argDebug):\n",
    "                print('  arrChannels.shape = {} ({})'.format(arrChannels.shape, type(arrChannels[0].item())))\n",
    "                print('  arrChannels[0] = {}'.format(arrChannels[0].item()))\n",
    "                print('  lstChannels = {}'.format(lstChannels))\n",
    "            \n",
    "            # See if matSegment[strSegLabel] has the 'sequence' data type.\n",
    "            # Looks like using dtype.names and dtype.fields give the same\n",
    "            # result -> what is the difference between the two?\n",
    "            if ('sequence' in matSegment[strSegLabel].dtype.names):\n",
    "                intSequence = matSegment[strSegLabel]['sequence'].item().item()\n",
    "            else:\n",
    "                intSequence = -1\n",
    "            if (argDebug): print('  intSequence = {}'.format(intSequence))\n",
    "            \n",
    "            print('  {}\\t{}\\t{}s\\t{}Hz\\t{}\\t{}\\t'.format(strSegLabel, arrData.shape, intSegDuration,\n",
    "                                                         intSamplingFreq, arrChannels.shape, intSequence))\n",
    "            \n",
    "            #for tupZip in zip(lstChannels, arrDataMax, arrDataMin, arrDataMean):\n",
    "            #    print('    {}\\t{}\\t{}\\t{:.4f}'.format(*tupZip))\n",
    "            #\n",
    "            #print()\n",
    "            \n",
    "            # Resample and round the results to the nearest integer since arrData[] is of type int16\n",
    "            arrDataResampled = np.rint(signal.resample(arrData, intResampledTimePts, axis = 1))  # Round all values to integers\n",
    "            if (argDebug): print('    arrDataResampled.shape = {} ({})'.format(arrDataResampled.shape, type(arrDataResampled[0][0])))\n",
    "            arrDataResampled = arrDataResampled.astype(int)  # Cast all values to type int\n",
    "            if (argDebug): print('    arrDataResampled.shape = {} ({})'.format(arrDataResampled.shape, type(arrDataResampled[0][0])))\n",
    "            \n",
    "            arrDataResampledMax  = np.max(arrDataResampled, axis = 1)\n",
    "            arrDataResampledMin  = np.min(arrDataResampled, axis = 1)\n",
    "            arrDataResampledMean = np.mean(arrDataResampled, axis = 1)\n",
    "            \n",
    "            for tupZip in zip(lstChannels, arrDataResampledMax, arrDataResampledMin, arrDataResampledMean):\n",
    "                print('    {}\\t{}\\t{}\\t{:.4f}'.format(*tupZip))\n",
    "            \n",
    "            # Reshape arrData[channels, time pts] into arrDataSplit[channels, subseq time pts, subsequences]\n",
    "            # where the subsequences are split along the 3rd dimension\n",
    "            arrDataSplit = arrDataResampled.reshape(intNumChannels, -1, intSubSeqTimePts)\n",
    "            arrDataSplit = np.swapaxes(arrDataSplit, 1, 2)\n",
    "            if (argDebug): print('    arrDataSplit.shape = {} ({})'.format(arrDataSplit.shape, type(arrDataSplit[0][0][0])))\n",
    "            \n",
    "            fltTotalDiff = 0\n",
    "            \n",
    "            # Loop through each subsequence and save the data and metadata into\n",
    "            # the appropriate data structures\n",
    "            for intSubSequence in np.arange(intNumSubSeqs):\n",
    "                # Group all segments processed into groups of data structures\n",
    "                lstAllSegLabels.append(strSegLabel)\n",
    "                lstAllSegTypes.append(intSegType)\n",
    "                #arrAllData[:, :, intNumProcessedFiles] = arrData\n",
    "                arrAllData[:, :, intAllDataIdx] = arrDataSplit[:, :, intSubSequence]\n",
    "                #lstAllSegDurations.append(intSegDuration)\n",
    "                lstAllSegDurations.append(argSubSeqDuration)   # Record the duration after the split\n",
    "                #lstAllSamplingFreqs.append(intSamplingFreq)\n",
    "                lstAllSamplingFreqs.append(argResamplingFreq)  # Record the resampled frequency\n",
    "                lstAllChannels.append(lstChannels)\n",
    "                lstAllSequences.append(intSequence)\n",
    "                lstAllSubSequences.append(intSubSequence)\n",
    "                \n",
    "                if (argDebug): print('    intSubSeg, intAllDataIdx = {}, {}'.format(intSubSequence, intAllDataIdx))\n",
    "                \n",
    "                # Test code to check that the data integrity is intact after the resampling and\n",
    "                # after the data split\n",
    "                if (argDebug):\n",
    "                    intStartIdx  = intSubSequence * intSubSeqTimePts\n",
    "                    intEndIdx    = (intSubSequence + 1) * intSubSeqTimePts\n",
    "                    fltDiffSplit = sum(arrDataResampled[0, intStartIdx:intEndIdx] - arrDataSplit[0, 0:intSubSeqTimePts, intSubSequence])\n",
    "                    fltDiffAll   = sum(arrDataSplit[0, 0:intSubSeqTimePts, intSubSequence] - arrAllData[0, 0:intSubSeqTimePts, intAllDataIdx])\n",
    "                    fltTotalDiff = fltTotalDiff + fltDiffSplit + fltDiffAll\n",
    "                \n",
    "                if (argDebug): print('      intStartIdx = {}, intEndIdx = {}, fltDiffSplit = {}, fltDiffAll = {}'.format(intStartIdx, intEndIdx, fltDiffSplit, fltDiffAll))\n",
    "                \n",
    "                intAllDataIdx = intAllDataIdx + 1\n",
    "            \n",
    "            if (argDebug): print('    fltTotalDiff = {}'.format(fltTotalDiff))\n",
    "            \n",
    "            intNumProcessedFiles = intNumProcessedFiles + 1\n",
    "            \n",
    "    print('intNumProcessedFiles = {}'.format(intNumProcessedFiles))\n",
    "    \n",
    "    # Make sure that the number of files that matched the specified\n",
    "    # extension is the same number of files that we actually processed\n",
    "    if (intNumMatchingFiles != intNumProcessedFiles):\n",
    "        print('WARNING: intNumMatchingFiles != intNumProcessedFiles!')\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('len(lstAllSegLabels) = {}'.format(len(lstAllSegLabels)))\n",
    "    print('len(lstAllSegTypes) = {}'.format(len(lstAllSegTypes)))\n",
    "    print('arrAllData.shape = {} ({}) (features x sequence length x batch size)'.format(arrAllData.shape,  type(arrAllData[0][0][0])))\n",
    "    print('len(lstAllSegDurations) = {}'.format(len(lstAllSegDurations)))\n",
    "    print('len(lstAllSamplingFreqs) = {}'.format(len(lstAllSamplingFreqs)))\n",
    "    print('len(lstAllChannels) = {}'.format(len(lstAllChannels)))\n",
    "    print('len(lstAllSequences) = {}'.format(len(lstAllSequences)))\n",
    "    print('len(lstAllSubSequences) = {}'.format(len(lstAllSubSequences)))\n",
    "\n",
    "    if (argDebug):\n",
    "        print('lstAllSegLabels = {}'.format(lstAllSegLabels))\n",
    "        print('lstAllSegTypes = {}'.format(lstAllSegTypes))\n",
    "        print('arrAllData = {}'.format(arrAllData))\n",
    "        print('lstAllSegDurations = {}'.format(lstAllSegDurations))\n",
    "        print('lstAllSamplingFreqs = {}'.format(lstAllSamplingFreqs))\n",
    "        print('lstAllChannels = {}'.format(lstAllChannels))\n",
    "        print('lstAllSequences = {}'.format(lstAllSequences))\n",
    "        print('lstAllSubSequences = {}'.format(lstAllSubSequences))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return lstBaseFilenames, lstAllSegLabels, lstAllSegTypes, arrAllData, lstAllSegDurations, lstAllSamplingFreqs, lstAllChannels, lstAllSequences, lstAllSubSequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib as pyedf\n",
    "\n",
    "# Read a single EDF file using PyEDFlib\n",
    "def fnReadEDFUsingPyEDFLib(argFullFilename, argPerformChecks = True, argReturnHeader = False, argNoData = False, argDebug = False):\n",
    "    # There is no need to call close() when using 'with' to open\n",
    "    # files\n",
    "    with pyedf.EdfReader(argFullFilename) as fhEDFFile:\n",
    "        \n",
    "        # The following are EDF-specific fields\n",
    "        objStartDatetime  = fhEDFFile.getStartdatetime()  # This is a datetime object\n",
    "        dictHeader        = fhEDFFile.getHeader()  # The EDF header is returned as a dictionary\n",
    "        \n",
    "        # TODO: Fill this in as 'interictal' if segment is outside of\n",
    "        #       the seizure annotation zone, and 'ictal' if within the\n",
    "        #       zone. How to label for 'preictal' is yet to be determined\n",
    "        \n",
    "        # This variable currently returns a dummy empty value, and\n",
    "        # the true segment label is determined by fnBreakCHBMITSegment()\n",
    "        # since each EDF file can be broken into segments of multiple\n",
    "        # EEG states based on whether there are seizure episodes\n",
    "        strSegLabel       = ''\n",
    "        \n",
    "        lstChannels = []\n",
    "        lstDiscardChannelID = []\n",
    "        intNumChannels = 0\n",
    "        intChannelOrigID = 0\n",
    "        \n",
    "        lstChannelsOrig   = fhEDFFile.getSignalLabels()\n",
    "        \n",
    "        # ***NOTE: Maybe we need to move this code one level up or put\n",
    "        #          it under a switch so that the check is data set\n",
    "        #          dependent\n",
    "        \n",
    "        # Exclude non-EEG channels\n",
    "        # Not an exhausted list here\n",
    "        # So far, we know those channels can be ECG, EKG and VNS\n",
    "        for strChannelLabel in lstChannelsOrig:\n",
    "            objInvalidCh = re.match(r'.*E[CK]G.*|.*VNS.*|\\s*-\\s*|\\s*\\.\\s*', strChannelLabel)\n",
    "            if (objInvalidCh):\n",
    "                lstDiscardChannelID.append(intChannelOrigID)\n",
    "                intChannelOrigID += 1\n",
    "                continue\n",
    "                \n",
    "            lstChannels.append(strChannelLabel)\n",
    "            intNumChannels   += 1\n",
    "            intChannelOrigID += 1\n",
    "            \n",
    "        if (argDebug and len(lstDiscardChannelID) > 0):\n",
    "            print('Discarded channels = {} (Indices = {})'.format(list(itemgetter(*lstDiscardChannelID)(lstChannelsOrig)), lstDiscardChannelID))\n",
    "            print('lstChannels = {}'.format(lstChannels))\n",
    "            print()\n",
    "            \n",
    "        lstChannelHeaders = fhEDFFile.getSignalHeaders()  # EDF-specific field (a list of dictionaries)\n",
    "        lstChannelHeaders = np.delete(lstChannelHeaders, lstDiscardChannelID)  # Remove discarded channels\n",
    "        \n",
    "        intNumChannelsOrig = fhEDFFile.signals_in_file  # Number of signals in the EDF file\n",
    "        \n",
    "        arrNumTimePts      = fhEDFFile.getNSamples()\n",
    "        arrNumTimePts      = np.delete(arrNumTimePts, lstDiscardChannelID)  # Remove discarded channels\n",
    "        \n",
    "        # Check for consistency of number of time points across all\n",
    "        # channels within the EDF file\n",
    "        intNumTimePts = 0\n",
    "        if (utils.fnAllIdentical1D(arrNumTimePts)):\n",
    "            intNumTimePts = arrNumTimePts[0]\n",
    "        else:\n",
    "            raise Exception('intNumTimePts are not identical across all channels!')\n",
    "        \n",
    "        arrData = np.zeros((intNumChannels, arrNumTimePts[0]), dtype = np.float64)\n",
    "        \n",
    "        # ***TODO: This loop is currently taking the most time to execute in this\n",
    "        #          function. I added a loop so that we can choose not to get data\n",
    "        #          from the EDF file. However, we may want to see if we can improve\n",
    "        #          the performance anyway\n",
    "        if (not argNoData):\n",
    "            intChannel = 0\n",
    "            # Loop through each channel and read the signal data into arrData[]\n",
    "            for intChannelOrig in np.arange(intNumChannelsOrig):\n",
    "                # if the channel is in the discard channel list, do not include its data\n",
    "                if (intChannelOrig not in lstDiscardChannelID):\n",
    "                    arrData[intChannel, :] = fhEDFFile.readSignal(intChannelOrig)\n",
    "                    intChannel += 1\n",
    "            \n",
    "        fltSegDuration    = fhEDFFile.getFileDuration()\n",
    "        \n",
    "        arrSamplingFreqs  = fhEDFFile.getSampleFrequencies()\n",
    "        arrSamplingFreqs  = np.delete(arrSamplingFreqs, lstDiscardChannelID)  # Remove discarded channels\n",
    "        \n",
    "        # Check for consistency of the sampling frequency across all\n",
    "        # channels within the EDF file\n",
    "        fltSamplingFreq = 0\n",
    "        if (utils.fnAllIdentical1D(arrSamplingFreqs)):\n",
    "            fltSamplingFreq = arrSamplingFreqs[0]\n",
    "        else:\n",
    "            raise Exception('fltSamplingFreqs are not identical across all channels!')\n",
    "            \n",
    "        # ***NOTE: With more data sets sharing this function, maybe we can expand\n",
    "        #          argPerformCheck to take additional values, such as 0 = no check,\n",
    "        #          1 = CHB-MIT, 2 = New_Data_2020, 3 = ...\n",
    "        \n",
    "        if (argPerformChecks):\n",
    "            # Extract sequence number from filename\n",
    "            objMatch = re.match(r'.+chb\\d+[a-zA-Z]*_(\\d+)[\\+a-zA-Z]*\\.edf', argFullFilename)  # ***BUG: Sequence number may be not alphanumeric?\n",
    "            if (objMatch == None):\n",
    "                raise Exception('argFullFilename does not match the required pattern!')\n",
    "\n",
    "            intSequence = int(objMatch.group(1))\n",
    "        else:\n",
    "            intSequence = 0\n",
    "        \n",
    "        if (argDebug):\n",
    "            print('objStartDatetime = {}\\n'.format(objStartDatetime))\n",
    "            print('dictHeader =\\n{}\\n'.format(dictHeader))\n",
    "            print('intNumChannels = {}\\n'.format(intNumChannels))\n",
    "            print('arrNumTimePts =\\n{}\\n'.format(arrNumTimePts))\n",
    "            print('intNumTimePts = {}\\n'.format(intNumTimePts))\n",
    "            print('arrData.shape = {}, type(arrData[0, 0]) = {}\\n'.format(arrData.shape, type(arrData[0, 0])))\n",
    "            print('fltSegDuration = {}s\\n'.format(fltSegDuration))\n",
    "            print('arrSamplingFreqs =\\n{}\\n'.format(arrSamplingFreqs))\n",
    "            print('fltSamplingFreq = {}Hz\\n'.format(fltSamplingFreq))\n",
    "            print('lstChannels =\\n{}\\n'.format(lstChannels))\n",
    "            print('len(lstChannelHeaders) = {}'.format(len(lstChannelHeaders)))\n",
    "            print('lstChannelHeaders[0] =\\n{}\\n'.format(lstChannelHeaders[0]))\n",
    "            print('intSequence = {}\\n'.format(intSequence))\n",
    "            print('arrData[0, 0:50] =\\n{}\\n'.format(arrData[0, 0:50]))\n",
    "            \n",
    "    if (argReturnHeader):\n",
    "        return strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts, dictHeader\n",
    "    else:\n",
    "        return strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnMatchEDFChannels(argFullEDFFiles, argDebug = False):\n",
    "\n",
    "    lstAllChannels   = []\n",
    "    blnMismatchFound = False\n",
    "    lstMismatches    = ['   ']\n",
    "    \n",
    "    # Loop through each file in argFullEDFFiles\n",
    "    for intFullFilenameIdx, strFullFilename in enumerate(argFullEDFFiles):\n",
    "        #print(intFullFilenameIdx, strFullFilename)\n",
    "        \n",
    "        # Get the data from each EDF file\n",
    "        strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts, dictEDFHeader = fnReadEDFUsingPyEDFLib(\n",
    "            strFullFilename, argPerformChecks = True, argReturnHeader = True, argNoData = True, argDebug = False)\n",
    "            \n",
    "        lstAllChannels.append(lstChannels)\n",
    "        \n",
    "        if (intFullFilenameIdx > 0):\n",
    "            if (lstAllChannels[intFullFilenameIdx] != lstAllChannels[intFullFilenameIdx - 1]):\n",
    "                blnMismatchFound = True\n",
    "                lstMismatches.append('***')\n",
    "            else:\n",
    "                lstMismatches.append('   ')\n",
    "                \n",
    "    if (blnMismatchFound or argDebug):\n",
    "        for intFullFilenameIdx, strFullFilename in enumerate(argFullEDFFiles):\n",
    "            print('In {}:\\n{} Ch = {}'.format(strFullFilename, lstMismatches[intFullFilenameIdx], lstAllChannels[intFullFilenameIdx]))\n",
    "            print()\n",
    "    else:\n",
    "        print('Channels match in all EDF files')\n",
    "        print()\n",
    "        \n",
    "    if (blnMismatchFound):\n",
    "        raise Exception('Channels do not match in EDF files!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of full EDF filenames, extract the statistics (min, max, and mean)\n",
    "# from each file (N) and each channel (C), returning three arrays of statistics\n",
    "# in C x N format. The statistics can be used for input data scaling\n",
    "def fnGetCHBMITStats(argFullTrainingFiles, argFullTestFiles = [], argDebug = False):\n",
    "\n",
    "    # Use the first EDF file in the list to get the number of channels. Assuming that\n",
    "    # the files in the rest of the list have the same channel arrangements and sampling\n",
    "    # rates\n",
    "    strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts, dictEDFHeader = fnReadEDFUsingPyEDFLib(\n",
    "        argFullTrainingFiles[0], argPerformChecks = True, argReturnHeader = True, argNoData = True, argDebug = False)\n",
    "        \n",
    "    intNumTrainingFiles = len(argFullTrainingFiles)\n",
    "    \n",
    "    # Assumption: if argFullTestFiles[] is specified, we assume that the number of\n",
    "    #             channels and the list of channels are the same between the training\n",
    "    #             and test files (which should be checked by the code that calls this\n",
    "    #             function)\n",
    "    if (argFullTestFiles):\n",
    "        intNumTestFiles = len(argFullTestFiles)\n",
    "    else:\n",
    "        intNumTestFiles = 0\n",
    "        \n",
    "    intNumTotalFiles = intNumTrainingFiles + intNumTestFiles\n",
    "    \n",
    "    # Initialize the data structures for storing the statistics\n",
    "    arrDataSetMin  = np.zeros((intNumChannels, intNumTotalFiles), dtype = np.float64)\n",
    "    arrDataSetMax  = np.zeros_like(arrDataSetMin)\n",
    "    arrDataSetMean = np.zeros_like(arrDataSetMin)\n",
    "    \n",
    "    argFullTotalFiles = argFullTrainingFiles + argFullTestFiles\n",
    "    if (argDebug):\n",
    "        print('len(argFullTotalFiles) = {}'.format(len(argFullTotalFiles)))\n",
    "        print()\n",
    "    \n",
    "    # Loop through each file in argFullTrainingFiles[] (and argFullTestFiles[], if specified)\n",
    "    for intFullFilenameIdx, strFullFilename in enumerate(argFullTotalFiles):\n",
    "        \n",
    "        # Get the data from each EDF file\n",
    "        strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts, dictEDFHeader = fnReadEDFUsingPyEDFLib(\n",
    "            strFullFilename, argPerformChecks = True, argReturnHeader = True, argNoData = False, argDebug = False)\n",
    "            \n",
    "        # Get the min, max, and mean for each file and each channel independently\n",
    "        arrDataMin  = np.min(arrData, axis = 1)\n",
    "        arrDataMax  = np.max(arrData, axis = 1)\n",
    "        arrDataMean = np.mean(arrData, axis = 1)\n",
    "        \n",
    "        # Group statistics in C (channel) x N (EDF file) \n",
    "        arrDataSetMin[:, intFullFilenameIdx]  = arrDataMin[:, np.newaxis].T\n",
    "        arrDataSetMax[:, intFullFilenameIdx]  = arrDataMax[:, np.newaxis].T\n",
    "        arrDataSetMean[:, intFullFilenameIdx] = arrDataMean[:, np.newaxis].T\n",
    "        \n",
    "        if (argDebug):\n",
    "            print('({}): strFullFilename = {}'.format(intFullFilenameIdx, strFullFilename))\n",
    "            print('        arrDataMin = {}'.format(pp.pformat(arrDataMin)))\n",
    "            print('        arrDataMax = {}'.format(pp.pformat(arrDataMax)))\n",
    "            print('        arrDataMean = {}'.format(pp.pformat(arrDataMean)))\n",
    "            print('        np.argmin(arrData, axis = 1) = {}'.format(np.argmin(arrData, axis = 1)))\n",
    "            print('        np.argmax(arrData, axis = 1) = {}'.format(np.argmax(arrData, axis = 1)))\n",
    "            print('        arrData[np.arange(arrData.shape[0]), np.argmin(arrData, axis = 1)] = {}'.format(arrData[np.arange(arrData.shape[0]), np.argmin(arrData, axis = 1)]))\n",
    "            print('        arrData[np.arange(arrData.shape[0]), np.argmax(arrData, axis = 1)] = {}'.format(arrData[np.arange(arrData.shape[0]), np.argmax(arrData, axis = 1)]))\n",
    "            print()\n",
    "            \n",
    "    if (argDebug):\n",
    "        print('arrDataSetMin = {}'.format(pp.pformat(arrDataSetMin)))\n",
    "        print('arrDataSetMax = {}'.format(pp.pformat(arrDataSetMax)))\n",
    "        print('arrDataSetMean = {}'.format(pp.pformat(arrDataSetMean)))\n",
    "        print()\n",
    "        \n",
    "    print('  arrDataSetMin.shape = {}, arrDataSetMax.shape = {}, arrDataSetMean.shape = {}'.format(\n",
    "        arrDataSetMin.shape, arrDataSetMax.shape, arrDataSetMean.shape))\n",
    "        \n",
    "    return arrDataSetMin, arrDataSetMax, arrDataSetMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate arrDataMin and arrDataMax from arrDataSetMin and arrDataSetMax based\n",
    "# on the desired scaling mode (argScalingMode). All these arrays have the same\n",
    "# shape, which is C (channel) x N (EDF file). argScalingMode can be specified to\n",
    "# scale by:\n",
    "#\n",
    "#   (1) Per channel and EDF file      (argScalingMode = 0)\n",
    "#   (2) Per channel, across EDF files (argScalingMode = 1)\n",
    "#   (3) Across channels, per EDF file (argScalingMode = 2)\n",
    "#   (4) Across channels and EDF files (argScalingMode = 3)\n",
    "#\n",
    "# Examples shown below:\n",
    "\n",
    "'''\n",
    "    argDataSetMin     argDataSetMax\n",
    "    -1, -4, -6, -3     1, 4, 8, 5\n",
    "    -2,  0, -1, -4     3, 4, 1, 6\n",
    "    -3, -2, -8, -5     2, 5, 9, 7\n",
    "    \n",
    "      argDataMin       argDataMax\n",
    "    -1, -4, -6, -3     1, 4, 8, 5\n",
    "    -2,  0, -1, -4     3, 4, 1, 6     -> per channel, per EDF file\n",
    "    -3, -2, -8, -5     2, 5, 9, 7\n",
    "    \n",
    "    -6, -6, -6, -6     8, 8, 8, 8\n",
    "    -4, -4, -4, -4     6, 6, 6, 6     -> per channel, across EDF files\n",
    "    -8, -8, -8, -8     9, 9, 9, 9\n",
    "    \n",
    "    -3, -4, -8, -5     3, 5, 9, 7\n",
    "    -3, -4, -8, -5     3, 5, 9, 7     -> across channels, per file\n",
    "    -3, -4, -8, -5     3, 5, 9, 7\n",
    "    \n",
    "    -8, -8, -8, -8     9, 9, 9, 9\n",
    "    -8, -8, -8, -8     9, 9, 9, 9     -> across channels and files\n",
    "    -8, -8, -8, -8     9, 9, 9, 9\n",
    "    \n",
    "'''\n",
    "\n",
    "def fnGenMinMaxArrays(argScalingMode, argDataSetMin, argDataSetMax, argDebug = False):\n",
    "    intNumChannels, intNumEDFFiles = argDataSetMin.shape\n",
    "    \n",
    "    # Per channel, across EDF files\n",
    "    if (argScalingMode == 1):\n",
    "        arrDataMin = np.repeat(np.min(argDataSetMin, axis = 1)[:, np.newaxis], intNumEDFFiles, axis = 1)\n",
    "        arrDataMax = np.repeat(np.max(argDataSetMax, axis = 1)[:, np.newaxis], intNumEDFFiles, axis = 1)\n",
    "        \n",
    "    # Across channels, per EDF file\n",
    "    elif (argScalingMode == 2):\n",
    "        arrDataMin = np.repeat(np.min(argDataSetMin, axis = 0)[np.newaxis, :], intNumChannels, axis = 0)\n",
    "        arrDataMax = np.repeat(np.max(argDataSetMax, axis = 0)[np.newaxis, :], intNumChannels, axis = 0)\n",
    "        \n",
    "    # Across channels and EDF files\n",
    "    elif (argScalingMode == 3):\n",
    "        arrDataMin = np.full((intNumChannels, intNumEDFFiles), np.min(argDataSetMin))\n",
    "        arrDataMax = np.full((intNumChannels, intNumEDFFiles), np.max(argDataSetMax))\n",
    "        \n",
    "    # Per channel and EDF file\n",
    "    else:\n",
    "        arrDataMin = argDataSetMin\n",
    "        arrDataMax = argDataSetMax\n",
    "    \n",
    "    print('  arrDataMin.shape = {}, arrDataMax.shape = {}'.format(arrDataMin.shape, arrDataMax.shape))\n",
    "    \n",
    "    if (argDebug):\n",
    "        print('  arrDataMin = {}'.format(pp.pformat(arrDataMin)))\n",
    "        print('  arrDataMax = {}'.format(pp.pformat(arrDataMax)))\n",
    "    \n",
    "    return arrDataMin, arrDataMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Read the binary annotation file from the CHB-MIT data set and return\n",
    "# a list of (start time, end time) tuples. The PhysioNet (which hosts\n",
    "# the CHB-MIT data set) Python library, wfdb, is required\n",
    "\n",
    "# The expected argFullFilename is the filename of the associated .edf\n",
    "# file, not the filename of the annotation!\n",
    "\n",
    "def fnReadCHBMITAnno(argFullFilename, argAnnoSuffix, argDebug = False):\n",
    "    # Check to see if there is an annotation file. If so, read the\n",
    "    # file and determine the seizure start and end time(s)\n",
    "    strFullFilename_Anno = argFullFilename + '.' + argAnnoSuffix\n",
    "    \n",
    "    blnAnnoFound = False\n",
    "    lstStartEndTimePts = []\n",
    "    \n",
    "    if (os.path.exists(strFullFilename_Anno)):\n",
    "        if (argDebug): print('  Annotation file found: {}'.format(strFullFilename_Anno))\n",
    "        \n",
    "        # Call the rdann() method to read the annotation file\n",
    "        objAnno = wfdb.rdann(argFullFilename, argAnnoSuffix)\n",
    "        \n",
    "        # Based on the number of pairs of markers returned (in case\n",
    "        # of multiple seizures), return multiple tuples in a list\n",
    "        intNumMarkers = objAnno.ann_len\n",
    "        arrStartEndSymbols = objAnno.symbol\n",
    "        arrStartEndTimePts = objAnno.sample\n",
    "        \n",
    "        # Raise an error if there is an odd number of markers\n",
    "        if ((intNumMarkers % 2) != 0):\n",
    "            raise Exception('Annotation markers are not all in pairs!')\n",
    "        \n",
    "        if (argDebug):\n",
    "            print('  intNumMarkers = {}, arrStartEndSymbols = {}, arrStartEndTimePts = {}'.format(intNumMarkers, arrStartEndSymbols, arrStartEndTimePts))\n",
    "        \n",
    "        blnAnnoFound = True\n",
    "        \n",
    "        # Pair up the seizure markers and start/end times based on\n",
    "        # whether they are odd or even items in the arrays, and return\n",
    "        # the pairs as tuples in a list\n",
    "        lstStartEndSymbols = list(zip(arrStartEndSymbols[0::2], arrStartEndSymbols[1::2]))\n",
    "        lstStartEndTimePts = list(zip(arrStartEndTimePts[0::2], arrStartEndTimePts[1::2]))\n",
    "        \n",
    "        if (argDebug):\n",
    "            print('  lstStartEndSymbols = {}'.format(lstStartEndSymbols))\n",
    "            print('  lstStartEndTimePts = {}'.format(lstStartEndTimePts))\n",
    "        \n",
    "        if (argDebug): wfdb.plot_wfdb(annotation = objAnno, time_units = 'minutes')\n",
    "        \n",
    "    return blnAnnoFound, lstStartEndTimePts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text annotation file from the CHB-MIT data set and return\n",
    "# a list of (start time, end time) tuples. The text annoation file is\n",
    "# generated by scrCHB-MITScripts.py\n",
    "\n",
    "# The expected argFullFilename is the filename of the associated .edf\n",
    "# file, not the filename of the annotation!\n",
    "\n",
    "def fnReadCHBMITAnnoTxt(argFullFilename, argAnnoSuffix, argSamplingFreq, argInfo = True, argDebug = False):\n",
    "    # Check to see if there is an annotation file. If so, read the\n",
    "    # file and determine the seizure start and end time(s)\n",
    "    strFullFilename_Anno = argFullFilename + '.' + argAnnoSuffix\n",
    "    \n",
    "    blnAnnoFound = False\n",
    "    lstStartEndTimePts = []\n",
    "    \n",
    "    if (os.path.exists(strFullFilename_Anno)):\n",
    "        if (argInfo): print('  Annotation file found: {}'.format(strFullFilename_Anno))\n",
    "        blnAnnoFound = True\n",
    "        \n",
    "        with open(strFullFilename_Anno) as objAnnoFile:\n",
    "            objAnnoReader = csv.reader(objAnnoFile, delimiter = ',')\n",
    "            intRow = 0\n",
    "\n",
    "            for lstRow in objAnnoReader:  # Read in the row from file\n",
    "                # Skip the first row of column names\n",
    "                if (intRow == 0):\n",
    "                    if (argDebug): print('Skipping the first row. Column names are: [{}]'.format(', '.join(lstRow)))\n",
    "                else:\n",
    "                    if (argDebug): print('lstRow = [{}] (len(lstRow) = {}) (type(lstRow) = {})'.format(lstRow, len(lstRow), type(lstRow)))\n",
    "                    \n",
    "                    # Skip empty rows, which are lists with len() = 0\n",
    "                    if (len(lstRow) > 0):\n",
    "                        fltStartTimeSec    = float(lstRow[0])\n",
    "                        fltSeizureDuration = float(lstRow[1])\n",
    "                        strAnnoType        = lstRow[2]\n",
    "                        \n",
    "                        intStartTimePt = int(round(fltStartTimeSec * argSamplingFreq))\n",
    "                        intEndTimePt   = int(round((fltStartTimeSec + fltSeizureDuration) * argSamplingFreq))\n",
    "                        \n",
    "                        lstStartEndTimePts.append((intStartTimePt, intEndTimePt))\n",
    "                        \n",
    "                intRow += 1\n",
    "                \n",
    "    return blnAnnoFound, lstStartEndTimePts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An over-simplified seizure cluster detection method. Currently,\n",
    "# it only determines whether there are multiple seizures within\n",
    "# the same segment\n",
    "def fnClusterDetection(argStartEndTimePts):\n",
    "    intNumSeizures = len(argStartEndTimePts)\n",
    "    \n",
    "    if (intNumSeizures > 1):\n",
    "        blnSeizureCluster = True\n",
    "    else:\n",
    "        blnSeizureCluster = False\n",
    "        \n",
    "    return blnSeizureCluster, intNumSeizures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaks a CHB-MIT segment (from a single EDF file) into multiple\n",
    "# segments based on the change in EEG state within the segment\n",
    "# (segment label and type). Uses the list of seizure start and end\n",
    "# time points from fnReadCHBMITAnno() as a starting point\n",
    "def fnBreakCHBMITSegment(argData, argStartEndTimePts, argSamplingFreq, argPreictalDuration = 5, argDebug = False):\n",
    "    \n",
    "    lstSegLabels        = []\n",
    "    lstSegTypes         = []\n",
    "    lstStartEndTimePts  = []\n",
    "    lstStartEndTimeSecs = []\n",
    "    lstSegDurations     = []\n",
    "    lstNumTimePts       = []\n",
    "    lstDataSegs         = []\n",
    "    \n",
    "    # Perform seizure cluster detection within a single EEG segment\n",
    "    blnSeizureCluster, intNumSeizures = fnClusterDetection(argStartEndTimePts)\n",
    "    \n",
    "    if (intNumSeizures > 0):\n",
    "        if (blnSeizureCluster):\n",
    "            print('  ***MULTIPLE SEIZURES DETECTED*** ', end = '')\n",
    "        else:\n",
    "            print('  ***SEIZURE DETECTED*** ', end = '')\n",
    "            \n",
    "        print('(Number of seizures = {})'.format(intNumSeizures))\n",
    "        print()\n",
    "        \n",
    "    # Get the start and end time point for the entire segment\n",
    "    intStartTimePt = 0\n",
    "    intEndTimePt = argData.shape[1]\n",
    "    print('  intStartTimePt = {}, intEndTimePt = {}'.format(intStartTimePt, intEndTimePt))\n",
    "\n",
    "    if (argDebug): print('  argStartEndTimePts = {}'.format(argStartEndTimePts))\n",
    "\n",
    "    lstSegTimePts = []\n",
    "    intNumSeizures = 0\n",
    "    \n",
    "    # If there are seizures within the segment, proceed to break it up\n",
    "    if (len(argStartEndTimePts) > 0):\n",
    "        # Loop through each seizure start/end time tuple and flatten\n",
    "        # all the time points into a single list\n",
    "        for tupStartEndTimePts in argStartEndTimePts:\n",
    "            intNumSeizures = intNumSeizures + 1\n",
    "\n",
    "            lstSegTimePts.extend([*tupStartEndTimePts])\n",
    "            #lstSegTimePts[-1] = lstSegTimePts[-1] + 1\n",
    "            \n",
    "            # If this is not the first seizure in the segment, insert\n",
    "            # an interictal segment in front of this seizure first\n",
    "            \n",
    "            # TODO: Depending on when the next seizure is, we may need\n",
    "            #       to label this as post-ictal or interictal-cluster\n",
    "            if (intNumSeizures > 1):\n",
    "                tupSegState = dctSegStates['interictal']\n",
    "                lstSegLabels.append(tupSegState[0])\n",
    "                lstSegTypes.append(tupSegState[1])\n",
    "                \n",
    "            # Label this segment as ictal\n",
    "            \n",
    "            # TODO: Depending on whether this is a lead seizure of not,\n",
    "            #       we may need to label this as ictal or ictal-cluster\n",
    "            tupSegState = dctSegStates['ictal']\n",
    "            lstSegLabels.append(tupSegState[0])\n",
    "            lstSegTypes.append(tupSegState[1])\n",
    "\n",
    "        if (argDebug): print('  lstSegTimePts = {}'.format(lstSegTimePts))\n",
    "        \n",
    "        # If the first time point of lstSegTimePts[] is not the same as\n",
    "        # the first time point of the entire segment, insert the very\n",
    "        # first time point to the beginning of the list\n",
    "        if (lstSegTimePts[0] != intStartTimePt):\n",
    "            lstSegTimePts.insert(0, intStartTimePt)\n",
    "            \n",
    "            # Label this newly inserted segment as interictal\n",
    "            \n",
    "            # TODO: Depending on when the previous and next seizures are,\n",
    "            #       we may need to label this as post-ictal or interictal-\n",
    "            #       cluster\n",
    "            tupSegState = dctSegStates['interictal']\n",
    "            lstSegLabels.insert(0, tupSegState[0])\n",
    "            lstSegTypes.insert(0, tupSegState[1])\n",
    "            \n",
    "        # If the last time point of lstSegTimePts[] is not the same as\n",
    "        # the last time point of the entire segment, append the very\n",
    "        # last time pount to the end of the list\n",
    "        if (lstSegTimePts[-1] != intEndTimePt):\n",
    "            lstSegTimePts.append(intEndTimePt)\n",
    "            \n",
    "            # TODO: Depending on when the next seizure this, we may need\n",
    "            #       to label this as post-ictal or interictal-cluster\n",
    "            tupSegState = dctSegStates['interictal']\n",
    "            lstSegLabels.append(tupSegState[0])\n",
    "            lstSegTypes.append(tupSegState[1])\n",
    "            \n",
    "    # Otherwise, simply label the segment as interictal\n",
    "    else:\n",
    "        lstSegTimePts.extend([intStartTimePt, intEndTimePt])\n",
    "        \n",
    "        tupSegState = dctSegStates['interictal']\n",
    "        lstSegLabels.append(tupSegState[0])\n",
    "        lstSegTypes.append(tupSegState[1])\n",
    "        \n",
    "    if (argDebug):\n",
    "        print('  lstSegTimePts = {}'.format(lstSegTimePts))\n",
    "        print('  lstSegLabels = {}'.format(lstSegLabels))\n",
    "        print('  lstSegTypes = {}'.format(lstSegTypes))\n",
    "        print()\n",
    "    \n",
    "    # Break and annotate the interictal segment immediately preceding an\n",
    "    # ictal segment into a preictal segment of length argPreictalDuration\n",
    "    # (in secs)\n",
    "    \n",
    "    # TODO: Go through each ictal segment, and if there is a preceding\n",
    "    #       interictal segment, label the last portion of that segment\n",
    "    #       (as specified by argPreictalDuration) as preictal\n",
    "    \n",
    "    # TODO: Depending on whether we only want to consider lead seizures,\n",
    "    #       the logic of this code may need to be modified\n",
    "    \n",
    "    # TODO: Maybe we can add an argument to generate an annotation file\n",
    "    #       for preictal states\n",
    "    \n",
    "    lstSegTimePtsPre = []\n",
    "    lstSegLabelsPre  = []\n",
    "    lstSegTypesPre   = []\n",
    "    \n",
    "    for intSegIdx in range(len(lstSegTimePts) - 1):\n",
    "        strSegLabel = lstSegLabels[intSegIdx]\n",
    "        intSegType  = lstSegTypes[intSegIdx]\n",
    "        \n",
    "        intStartTimePt = lstSegTimePts[intSegIdx]\n",
    "        intEndTimePt = lstSegTimePts[intSegIdx + 1]\n",
    "        \n",
    "        if (argDebug): print('  intStartTimePt = {}, intEndTimePt = {}'.format(intStartTimePt, intEndTimePt))\n",
    "        \n",
    "        if (fnIsSegState('ictal', intSegType) and intSegIdx > 0):\n",
    "            strSegLabelPrev = lstSegLabels[intSegIdx - 1]\n",
    "            intSegTypePrev  = lstSegTypes[intSegIdx - 1]\n",
    "            \n",
    "            intStartTimePtPrev = lstSegTimePts[intSegIdx - 1]\n",
    "            intEndTimePtPrev = lstSegTimePts[intSegIdx]\n",
    "            \n",
    "            if (argDebug): print('  intStartTimePtPrev = {}, intEndTimePtPrev = {}'.format(intStartTimePtPrev, intEndTimePtPrev))\n",
    "            \n",
    "            if (fnIsSegState('interictal', intSegTypePrev)):\n",
    "                tupPreictal = dctSegStates['preictal']\n",
    "                \n",
    "                intNumPreictalTimePts = argPreictalDuration * argSamplingFreq\n",
    "                intStartTimePtPreictal = intEndTimePtPrev - intNumPreictalTimePts\n",
    "                intEndTimePtPreictal = intEndTimePtPrev\n",
    "                \n",
    "                lstSegTimePtsPre.pop()\n",
    "                lstSegTimePtsPre.extend([intStartTimePtPreictal, intEndTimePtPreictal])\n",
    "                lstSegLabelsPre.append(tupPreictal[0])\n",
    "                lstSegTypesPre.append(tupPreictal[1])\n",
    "                \n",
    "        lstSegTimePtsPre.extend([intStartTimePt, intEndTimePt])\n",
    "        lstSegLabelsPre.append(strSegLabel)\n",
    "        lstSegTypesPre.append(intSegType)\n",
    "        \n",
    "    if (argDebug):\n",
    "        print('  lstSegTimePtsPre = {}'.format(lstSegTimePtsPre))\n",
    "        print('  lstSegLabelsPre = {}'.format(lstSegLabelsPre))\n",
    "        print('  lstSegTypesPre = {}'.format(lstSegTypesPre))        \n",
    "        \n",
    "    print()\n",
    "    \n",
    "    # Loop through lstSegTimePts[] in tandem with lstSegLabels[] and\n",
    "    # lstSegTypes[] to generate the start and end time points of each\n",
    "    # subsegment based on its EEG state, and break the segment data up\n",
    "    # based on each subsegment's duration\n",
    "    for intSegIdx in range(len(lstSegTimePts) - 1):\n",
    "        strSegLabel = lstSegLabels[intSegIdx]\n",
    "        intSegType  = lstSegTypes[intSegIdx]\n",
    "        \n",
    "        intStartTimePt = lstSegTimePts[intSegIdx]\n",
    "        intEndTimePt = lstSegTimePts[intSegIdx + 1]\n",
    "        \n",
    "        fltStartTimeSec = intStartTimePt / argSamplingFreq\n",
    "        fltEndTimeSec = intEndTimePt / argSamplingFreq\n",
    "\n",
    "        intNumTimePts = intEndTimePt - intStartTimePt\n",
    "        fltSegDuration = fltEndTimeSec - fltStartTimeSec\n",
    "        \n",
    "        lstStartEndTimePts.append((intStartTimePt, intEndTimePt))\n",
    "        lstStartEndTimeSecs.append((fltStartTimeSec, fltEndTimeSec))\n",
    "        lstSegDurations.append(fltSegDuration)\n",
    "        lstNumTimePts.append(intNumTimePts)\n",
    "        lstDataSegs.append(argData[:, intStartTimePt:intEndTimePt])\n",
    "        \n",
    "        if (fnIsSegState('ictal', intSegType)):\n",
    "            print('  [***{}***:\\t'.format(strSegLabel.upper()), end = '')\n",
    "        else:\n",
    "            #print('  [{}]:  '.format(strSegLabel), end = '')\n",
    "            print('  [\\t\\t'.format(strSegLabel), end = '')\n",
    "            \n",
    "        #print('{:.6f}s ({}) -> {:.6f}s ({}), duration = {:.6f}s ({}), data shape = {}]'.format(fltStartTimeSec, intStartTimePt, fltEndTimeSec, intEndTimePt, fltSegDuration, intNumTimePts, lstDataSegs[-1].shape))\n",
    "        print('{}s ({}) -> {}s ({}), duration = {}s ({}), data shape = {}]'.format(fltStartTimeSec, intStartTimePt, fltEndTimeSec, intEndTimePt, fltSegDuration, intNumTimePts, lstDataSegs[-1].shape))\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    return lstSegLabels, lstSegTypes, lstStartEndTimePts, lstStartEndTimeSecs, lstSegDurations, lstNumTimePts, lstDataSegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one or more EEG segments from the CHB-MIT data set from\n",
    "# files (.edf) based on which files are specified in argCSVPath\n",
    "\n",
    "# The units of argResamplingFreq is in Hz and argSubSeqDuration is in\n",
    "# seconds\n",
    "\n",
    "# NOTE: Subjects under 3 yrs old, i.e. chb06 (1.5 yrs old) and chb12 (2 yrs old),\n",
    "# should be excluded, according to Jeffrey, since the base frequency of their EEGs\n",
    "# have yet reached the adult level of 8.5Hz\n",
    "\n",
    "def fnReadCHBMITEDFFiles_SlidingWindow(argCSVPath, argTestCSVPath = '', argResamplingFreq = -1, argSubSeqDuration = -1, argScalingParams = (), argScalingInfo = (), argStepSizeTimePts = -1, argStepSizeStates = {}, argSubWindowFraction = -1, argAnnoSuffix = 'seizures', argDebug = False, argTestMode = False):\n",
    "    lstMatchingFiles = fnReadDataFileListCSV(argCSVPath)\n",
    "    \n",
    "    if (argTestCSVPath):\n",
    "        lstMatchingTestFiles = fnReadDataFileListCSV(argTestCSVPath)\n",
    "    else:\n",
    "        lstMatchingTestFiles = []\n",
    "    \n",
    "    intNumMatchingFiles = len(lstMatchingFiles)  # Number of matching training files\n",
    "    intNumMatchingTestFiles = len(lstMatchingTestFiles)  # Number of matching test files\n",
    "    \n",
    "    if (argDebug):\n",
    "        print('intNumMatchingFiles = {}, intNumMatchingTestFiles = {}'.format(intNumMatchingFiles, intNumMatchingTestFiles))\n",
    "        print()\n",
    "    \n",
    "    # Check whether there are mismatched channels in all EDF files\n",
    "    fnMatchEDFChannels(lstMatchingFiles)\n",
    "    \n",
    "    # Read the first .edf file to extract parameters that are global\n",
    "    # across the data set\n",
    "    \n",
    "    # NOTE: For EDF files, it is possible that for each segment, each\n",
    "    #       channel can have different:\n",
    "    #         (1) number of time points/segment lengths, and\n",
    "    #         (2) sampling frequencies\n",
    "    #\n",
    "    #       And at a patient level, it is also possible that different\n",
    "    #       segments have different:\n",
    "    #         (4) number of channels\n",
    "    #         (5) number of time points\n",
    "    #         (6) sampling frequencies\n",
    "    #\n",
    "    #       For the CHB-MIT data set, only (5) is true, so we will need\n",
    "    #       to handle different segment lengths as we read in each EDF\n",
    "    #       file, and assume that the other parameters are global. This\n",
    "    #       will simplify the code somewhat without having to handle all\n",
    "    #       these parameters as variables for each EDF file\n",
    "    #\n",
    "    #       ***TODO***:\n",
    "    #       HOWEVER, at a data set level, the number of channels across\n",
    "    #       different patients can be different. If we want to train a\n",
    "    #       generalized model, we will have to find the minimum montage\n",
    "    #       that is common across a set of patients. We currently do not\n",
    "    #       have the code to handle this situation\n",
    "    \n",
    "    strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts = fnReadEDFUsingPyEDFLib(lstMatchingFiles[0], argDebug = True)\n",
    "    \n",
    "    # If argResamplingFreq = -1 (default) or argResamplingFreq > intSamplingFreq,\n",
    "    # use the *first* sampling frequency (upsampling is not allowed for now)\n",
    "    if ((argResamplingFreq == -1) or (argResamplingFreq > fltSamplingFreq)):\n",
    "        argResamplingFreq = fltSamplingFreq        \n",
    "    print('argResamplingFreq = {}Hz'.format(argResamplingFreq))\n",
    "    \n",
    "    # If argSubSeqDuration = -1 (default) or argSubSeqDuration > intSegDuration,\n",
    "    # default back to the *first* segment duration\n",
    "    if ((argSubSeqDuration == -1) or (argSubSeqDuration > fltSegDuration)):\n",
    "        argSubSeqDuration = fltSegDuration  # Do not break segment into subsequences\n",
    "    print('argSubSeqDuration = {}s'.format(argSubSeqDuration))\n",
    "    \n",
    "    # Calculate the number of time points in each segment after splitting up the segment\n",
    "    # into shorter sequences\n",
    "    intSubSeqTimePts = int(round(argSubSeqDuration * fltSamplingFreq))\n",
    "    intResampledSubSeqTimePts = int(round(argSubSeqDuration * argResamplingFreq))\n",
    "    print('intSubSeqTimePts = {}, intResampledSubSeqTimePts = {}'.format(intSubSeqTimePts, intResampledSubSeqTimePts))\n",
    "        \n",
    "    # If argStepSizeTimePts = -1 (default) or argStepSizeTimePts > intSubSeqTimePts,\n",
    "    # default back to the *first* segment time points\n",
    "    if ((argStepSizeTimePts == -1) or (argStepSizeTimePts > intSubSeqTimePts)):\n",
    "        argStepSizeTimePts = intSubSeqTimePts  # No sliding window\n",
    "    print('argStepSizeTimePts = {}'.format(argStepSizeTimePts))\n",
    "    \n",
    "    # If argSubWindowFraction = -1 (default) or argSubWindowFraction <= 0 or > 1,\n",
    "    # default to the entire window size (intSubSeqTimePts)\n",
    "    if ((argSubWindowFraction == -1) or (argSubWindowFraction <= 0) or (argSubWindowFraction > 1)):\n",
    "        argSubWindowFraction = 1.0\n",
    "    print('argSubWindowFraction = {}'.format(argSubWindowFraction))\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    # Initialize data structures to store data for the entire data set\n",
    "    lstAllBaseFilenames = []  # List of segment filenames\n",
    "    lstAllSegLabels = []      # List of segment labels\n",
    "    lstAllSegTypes = []       # List of segment types (preictal = 1 or interictal = 2)\n",
    "    \n",
    "    # NOTE: arrAllData[] can no longer be initialized prior to reading all the\n",
    "    #       segments, as each segment are now allowed to have a different length\n",
    "    #       (intNumTimePts), so each segment may be split into a different number\n",
    "    #       of subsequences (intNumFullSubSeqs). Therefore, we can no longer\n",
    "    #       calculate the total number of subsequences (intTotalBatchSize) based\n",
    "    #       on the number of sequences (intNumMatchingFiles) and the number of\n",
    "    #       subsequences per file (intNumSubSeqs)\n",
    "    #\n",
    "    #       Instead, we will create arrAllData[] with a fixed number of channels\n",
    "    #       and subsequence time points (both of which are expected to be\n",
    "    #       consistent across the data set), and a 3rd dimension with zero size\n",
    "    #       that we will append the subsequences to as we loop through each file\n",
    "    #\n",
    "    #       intTotalBatchSize = intNumMatchingFiles * intNumSubSeqs  # Total number of sequences\n",
    "    \n",
    "    # ***TEST MODE:\n",
    "    if (argTestMode):\n",
    "        intSubSeqTimePts = 8  # Window size\n",
    "        argSubWindowFraction = 0.5\n",
    "\n",
    "    arrAllData = np.zeros((intNumChannels, intSubSeqTimePts, 0), dtype = np.float64)\n",
    "    if (argDebug):\n",
    "        print('arrAllData.shape = {}'.format(arrAllData.shape))\n",
    "        print()\n",
    "    \n",
    "    lstAllSegDurations  = []  # List of segment durations (in seconds)\n",
    "    lstAllSamplingFreqs = []  # List of sampling frequencies (in Hz)\n",
    "    lstAllChannels      = []  # List of lists (of channel names)\n",
    "    lstAllSequences     = []  # List of sequence indices\n",
    "    lstAllSubSequences  = []  # List of subsequence indices (if one sequence is broken up into subsequences)\n",
    "    \n",
    "    # List of start/end time points and times (in seconds) for each subsequence\n",
    "    arrAllStartEndTimePts  = np.zeros((0, 2))\n",
    "    arrAllStartEndTimesSec = np.zeros((0, 2), dtype = np.float64)\n",
    "    \n",
    "    lstSeizureDurations = []  # List of seizure durations (in seconds) (not broken into subsequences)\n",
    "    \n",
    "    datLoopStart = utils.fnNow()\n",
    "    print('Loop started on {}'.format(utils.fnGetDatetime(datLoopStart)))\n",
    "    print()\n",
    "    \n",
    "    intNumProcessedFiles = 0\n",
    "    fltFirstSamplingFreq = fltSamplingFreq  # Remember the sampling frequency of the first file\n",
    "    lstFirstChannels = lstChannels          # Remember the list of channels of the first file\n",
    "    \n",
    "    print('fltFirstSamplingFreq = {}Hz'.format(fltFirstSamplingFreq))\n",
    "    print('lstFirstChannels = {}'.format(lstFirstChannels))\n",
    "    print()\n",
    "    \n",
    "    # SCALING\n",
    "    if (argScalingParams):\n",
    "        intScalingMode  = argScalingParams[0]\n",
    "        tupScaledMinMax = argScalingParams[1]\n",
    "        print('Scaling data using: intScalingMode = {}, tupScaledMinMax = {}'.format(intScalingMode, tupScaledMinMax))\n",
    "        \n",
    "        if (argScalingInfo):\n",
    "            print('  Scaling using argScalingInfo({}, {}, {})'.format(len(argScalingInfo[0]), argScalingInfo[1].shape, argScalingInfo[2].shape))\n",
    "            \n",
    "            arrDataMin = argScalingInfo[1]\n",
    "            arrDataMax = argScalingInfo[2]\n",
    "            \n",
    "        else:\n",
    "            # TODO: Currently we are reading in the same data set twice, so this is not speed\n",
    "            #       efficient. Maybe we should combine these two loops into one    \n",
    "            # SCALING: Collect the statistics of the specified EDF files\n",
    "            arrDataSetMin, arrDataSetMax, arrDataSetMean = fnGetCHBMITStats(lstMatchingFiles, lstMatchingTestFiles, argDebug = False)\n",
    "\n",
    "            # Construct arrDataMin and arrDataMax based on the scaling mode\n",
    "            arrDataMin, arrDataMax = fnGenMinMaxArrays(intScalingMode, arrDataSetMin, arrDataSetMax, argDebug = False)\n",
    "            \n",
    "    else:\n",
    "        print('Data scaling is not performed')\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    # ***TEST MODE:\n",
    "    if (argTestMode):\n",
    "        lstMatchingFiles = lstMatchingFiles[0:1]\n",
    "    \n",
    "    # Loop through each file in the target directory\n",
    "    for intFullFilenameIdx, strFullFilename in enumerate(lstMatchingFiles):  # SCALING\n",
    "        # Process only .edf files\n",
    "        if strFullFilename.endswith('.edf'):\n",
    "            print('Processing {}...'.format(strFullFilename))\n",
    "            \n",
    "            # Extract the filename from the full path\n",
    "            strPath, strFilename = os.path.split(strFullFilename)\n",
    "            \n",
    "            # Read the .edf file\n",
    "            strSegLabel, arrDataEDF, fltSegDurationEDF, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePtsEDF = fnReadEDFUsingPyEDFLib(strFullFilename, argDebug = False)\n",
    "            print('  fltSegDurationEDF = {}s, fltSampingFreq = {}Hz'.format(fltSegDurationEDF, fltSamplingFreq))\n",
    "            print()\n",
    "            \n",
    "            if (argScalingParams):\n",
    "                # SCALING: Construct arrDataMinMax (C x 2) from arrDataMin and arrDataMax\n",
    "                #          (C x N)\n",
    "                # SCALING (normalize, filter, smoothing(?), augment (later))\n",
    "                arrDataMinMax = np.concatenate((arrDataMin[:, intFullFilenameIdx][:, np.newaxis], arrDataMax[:, intFullFilenameIdx][:, np.newaxis]), axis = 1)\n",
    "                if (argDebug):\n",
    "                    print('  arrDataMinMax.shape = {}'.format(arrDataMinMax.shape))\n",
    "                    print()\n",
    "                \n",
    "                arrDataEDFScaled = utils.fnMinMaxScaler(arrDataEDF, tupScaledMinMax, arrDataMinMax, argDebug = False)\n",
    "            else:\n",
    "                arrDataEDFScaled = arrDataEDF\n",
    "                \n",
    "            # Consistency check for sampling rate and channel labels\n",
    "            if (fltSamplingFreq != fltFirstSamplingFreq):\n",
    "                raise Exception('Sampling frequency not consistent across the data segments!')\n",
    "                \n",
    "            if (lstChannels != lstFirstChannels):\n",
    "                raise Exception('Channels not consistent across the data segments!')\n",
    "            \n",
    "            # Check to see if an annotation file (.seizures) exists. If so, set strSegLabel\n",
    "            # and determine the seizure start/end times\n",
    "            \n",
    "            # TODO: Change argAnnoSuffix to argReadAnnoTxt (boolean) to call fnReadCHBMITAnno()\n",
    "            #       to read binary 'seizures' files when false, and call fnReadCHBMITAnnoTxt()\n",
    "            #       to read ASCII 'annotation.txt' files when true\n",
    "            #blnAnnoFound, lstStartEndTimePts = fnReadCHBMITAnno(strFullFilename, argAnnoSuffix)\n",
    "            blnAnnoFound, lstStartEndTimePts = fnReadCHBMITAnnoTxt(strFullFilename, argAnnoSuffix, fltSamplingFreq)\n",
    "            \n",
    "            # SCALING\n",
    "            # Break the segment up based on their respective segment types\n",
    "            lstSegLabels, lstSegTypes, lstStartEndTimePts, lstStartEndTimeSecs, lstSegDurations, lstNumTimePts, lstDataSegs = fnBreakCHBMITSegment(arrDataEDFScaled, lstStartEndTimePts, fltSamplingFreq, argDebug = True)\n",
    "            \n",
    "            if (argDebug):\n",
    "                print('   lstSegLabels = {}'.format(lstSegLabels))\n",
    "                print('   lstSegTypes = {}'.format(lstSegTypes))\n",
    "                print('   lstStartEndTimePts = {}'.format(lstStartEndTimePts))\n",
    "                print('   lstStartEndTimeSecs = {}'.format(lstStartEndTimeSecs))\n",
    "                print('   lstSegDurations = {}'.format(lstSegDurations))\n",
    "                print('   lstNumTimePts = {}'.format(lstNumTimePts))\n",
    "                print('   len(lstDataSegs) = {}'.format(len(lstDataSegs)))  # TODO: No longer used due to sliding window\n",
    "                print()\n",
    "            \n",
    "            # ***TEST MODE:\n",
    "            if (argTestMode):\n",
    "                argStepSizeTimePts = 6\n",
    "                #argStepSizeStates = {}\n",
    "                argStepSizeStates = {'ictal': 2}\n",
    "                \n",
    "                #lstSegLabels = ['interictal', 'ictal', 'interictal']\n",
    "                #lstStartEndTimePts = [(0, 30), (30, 70), (70, 100)]\n",
    "\n",
    "                lstSegLabels = ['interictal', 'ictal', 'interictal', 'ictal', 'interictal']\n",
    "                lstStartEndTimePts = [(0, 30), (30, 50), (50, 60), (60, 80), (80, 100)]\n",
    "                \n",
    "                intNumTimePtsEDF = lstStartEndTimePts[-1][1] - lstStartEndTimePts[0][0]\n",
    "                \n",
    "                # Create a data array filled with zeros except for the first 2 channels,\n",
    "                # for debugging purposes\n",
    "                arrDataEDFScaled = np.zeros((intNumChannels, intNumTimePtsEDF))\n",
    "                arrDataEDFScaled[0, :] = np.arange(intNumTimePtsEDF)\n",
    "                arrDataEDFScaled[1, :] = np.arange(intNumTimePtsEDF)\n",
    "                \n",
    "                lstSegTypes = []\n",
    "                for strSegLabel in lstSegLabels:\n",
    "                    lstSegTypes.append(fnGetSegType(strSegLabel))\n",
    "                    \n",
    "                lstStartEndTimeSecs = []\n",
    "                for tupStartEndTimePts in lstStartEndTimePts:\n",
    "                    lstStartEndTimeSecs.append(tuple((intTimePt / fltSamplingFreq) for intTimePt in tupStartEndTimePts))\n",
    "                \n",
    "                lstSegDurations = []\n",
    "                for fltStartTimeSec, fltEndTimeSec in lstStartEndTimeSecs:\n",
    "                    lstSegDurations.append(fltEndTimeSec - fltStartTimeSec)\n",
    "                \n",
    "                lstNumTimePts = []\n",
    "                for intTupIdx, tupStartEndTimePts in enumerate(lstStartEndTimePts):\n",
    "                    lstNumTimePts.append(lstStartEndTimePts[intTupIdx][1] - lstStartEndTimePts[intTupIdx][0])\n",
    "                    \n",
    "                lstDataSegs = []\n",
    "                for intNumTimePts in lstNumTimePts:\n",
    "                    lstDataSegs.append(np.zeros((arrDataEDFScaled.shape[0], intNumTimePts)))\n",
    "                \n",
    "                print('   *****************')\n",
    "                print('   *** TEST MODE ***')\n",
    "                print('   *****************')\n",
    "                \n",
    "                if (len(lstSegTypes) != len(lstStartEndTimePts)):\n",
    "                    print('\\n   WARNING: len(lstSegTypes) != len(lstStartEndTimePts)!\\n')\n",
    "                \n",
    "                print('   intSubSeqTimePts = {}, argStepSizeTimePts = {}, argStepSizeStates = {}, argSubWindowFraction = {}, intNumTimePtsEDF = {}'.format(\n",
    "                    intSubSeqTimePts, argStepSizeTimePts, argStepSizeStates, argSubWindowFraction, intNumTimePtsEDF))\n",
    "                print()\n",
    "                \n",
    "                print('   lstSegLabels = {}, lstSegTypes = {}'.format(lstSegLabels, lstSegTypes))\n",
    "                print('   lstStartEndTimePts = {}, lstNumTimePts = {}'.format(lstStartEndTimePts, lstNumTimePts))\n",
    "                print('   lstStartEndTimeSecs = {}'.format(lstStartEndTimeSecs))\n",
    "                print('   lstSegDurations = {}'.format(lstSegDurations))\n",
    "                print('   len(lstDataSegs) = {}'.format(len(lstDataSegs)))  # TODO: No longer used due to sliding window\n",
    "                print()\n",
    "                \n",
    "            # Create an array with same size as the entire segment with each time\n",
    "            # point filled with intSegType\n",
    "            arrSegTypeTimePts = np.zeros((intNumTimePtsEDF), dtype = np.int)\n",
    "            \n",
    "            for intSegIdx, tupSeg in enumerate(zip(lstSegTypes, lstStartEndTimePts)):\n",
    "                intSegType, tupStartEndTimePt = [*tupSeg]\n",
    "                \n",
    "                intStartTimePt, intEndTimePt = tupStartEndTimePt\n",
    "                print('   intStartTimePt = {} -> intEndTimePt = {}: intSegType = {}'.format(intStartTimePt, intEndTimePt, intSegType))\n",
    "                \n",
    "                arrSegTypeTimePts[intStartTimePt:intEndTimePt] = intSegType\n",
    "                \n",
    "            print()\n",
    "            print('   arrSegTypeTimePts = {} (shape = {}'.format(arrSegTypeTimePts, arrSegTypeTimePts.shape))\n",
    "            print()\n",
    "            \n",
    "            print('  argStepSizeStates = {}'.format(argStepSizeStates))\n",
    "            \n",
    "            # Create a list of intStepSizeTimePts that correspond to intSegType of each segment\n",
    "            lstStepSizeTimePts = []\n",
    "            for intSegLabel in lstSegLabels:\n",
    "                if intSegLabel in argStepSizeStates.keys():\n",
    "                    lstStepSizeTimePts.append(argStepSizeStates[intSegLabel])\n",
    "                else:\n",
    "                    lstStepSizeTimePts.append(argStepSizeTimePts)\n",
    "                    \n",
    "            print('  lstStepSizeTimePts = {}'.format(lstStepSizeTimePts))\n",
    "            print()\n",
    "            \n",
    "            # Loop through each segment to generate the appropriate subsequences \n",
    "            for intSegIdx, tupSeg in enumerate(zip(lstSegLabels, lstSegTypes, lstStartEndTimePts, lstStartEndTimeSecs, lstSegDurations, lstNumTimePts, lstDataSegs)):\n",
    "                strSegLabel, intSegType, tupStartEndTimePt, tupStartEndTimeSec, fltSegDuration, intNumTimePts, arrDataSeg = [*tupSeg]\n",
    "                \n",
    "                # Extract the start and end time points of each segment\n",
    "                intStartTimePt, intEndTimePt   = tupStartEndTimePt\n",
    "                fltStartTimeSec, fltEndTimeSec = tupStartEndTimeSec\n",
    "                \n",
    "                # Get the intStepSizeTimePts for the current segment\n",
    "                intStepSizeTimePts = lstStepSizeTimePts[intSegIdx]\n",
    "                \n",
    "                # Synchronize the start of the sliding window to the beginning of each segment\n",
    "                intWindowStartTimePt = intStartTimePt  # Start time point of the first window\n",
    "                intWindowEndTimePt = intWindowStartTimePt + intSubSeqTimePts  # End time point of the first window\n",
    "            \n",
    "                if (fnIsSegState('ictal', intSegType)):\n",
    "                    lstSeizureDurations.append((strFilename, fltSegDuration))\n",
    "                    print('  => SEGMENT ({}) = ***{}*** (intStepSizeTimePts = {})'.format(intSegIdx + 1, strSegLabel.upper(), intStepSizeTimePts))\n",
    "                else:\n",
    "                    print('  => SEGMENT ({}) = {} (intStepSizeTimePts = {})'.format(intSegIdx + 1, strSegLabel.upper(), intStepSizeTimePts))\n",
    "                    \n",
    "                print('    {:.6f}s ({}) -> {:.6f}s ({}), duration = {:.6f}s ({}), arrDataSeg.shape = {}'.format(fltStartTimeSec, intStartTimePt, fltEndTimeSec, intEndTimePt, fltSegDuration, intNumTimePts, arrDataSeg.shape))\n",
    "                print()\n",
    "                \n",
    "                # Analyze the number of subsequences to break down from the main segment, and\n",
    "                # whether the time points can be equally divided among all the subsequences\n",
    "                #\n",
    "                # Calculations specific for sliding window, inspired by:\n",
    "                #\n",
    "                #   http://cs231n.github.io/convolutional-networks/\n",
    "                #\n",
    "                # on how to calculate padding for CNNs. In this case, we assume zero-padding\n",
    "                # by setting P = 0:\n",
    "                #\n",
    "                #   ((W − F + 2P)/S) + 1\n",
    "                #\n",
    "                # where P = padding size, W = input width of layer, F = output width of layer,\n",
    "                # and S = stride\n",
    "                #\n",
    "                #fltNumSubSeqs = ((intNumTimePts - intSubSeqTimePts) / intStepSizeTimePts) + 1\n",
    "                \n",
    "                # If we're not in the last segment there is no need to calculate using the\n",
    "                # sliding window formula specified above since the window can slide past the\n",
    "                # current segment and into the next time\n",
    "                if (intSegIdx <  len(lstStartEndTimePts) - 1):\n",
    "                    intNumSubSeqs = math.ceil(intNumTimePts / intStepSizeTimePts)  # Total number of subsequences required\n",
    "                    intNumFullSubSeqs = intNumSubSeqs                              # Number of completely filled subsequences\n",
    "                    intNumOrphanTimePts = 0                                        # Number of orphan time points\n",
    "                else:\n",
    "                    intNumSubSeqs = math.ceil((intNumTimePts - intSubSeqTimePts) / intStepSizeTimePts) + 1  # Total number of subsequences required\n",
    "                    intNumFullSubSeqs = ((intNumTimePts - intSubSeqTimePts) // intStepSizeTimePts) + 1      # Number of completely filled subsequences\n",
    "                    intNumOrphanTimePts = (intNumTimePts - intSubSeqTimePts) % intStepSizeTimePts           # Number of orphan time points\n",
    "\n",
    "                    #intPadding = ((intNumSubSeqs - 1) * intStepSizeTimePts) - intNumTimePts + intSubSeqTimePts\n",
    "                    #if (argDebug): print('intPadding = {}'.format(intPadding))\n",
    "                    \n",
    "                # If the number of subsequence time points specified results in the\n",
    "                # last subsequence not being completely filled up, give a warning message\n",
    "                if (intNumOrphanTimePts > 0):\n",
    "                    print('     WARNING: Time points cannot be divided into complete subsequences')\n",
    "\n",
    "                if (intNumFullSubSeqs > 1):\n",
    "                    print('     Splitting each segment into {} subsequences based on intSubSeqTimePts = {} and intStepSizeTimePts = {}'.format(intNumFullSubSeqs, intSubSeqTimePts, intStepSizeTimePts))\n",
    "                    \n",
    "                strLastSegment = ' (last segment)' if (intSegIdx ==  len(lstStartEndTimePts) - 1) else ''\n",
    "                print('     [intSegIdx = {}{}: intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts = {} / {} / {} ({:.2f}%)]'.format(intSegIdx, strLastSegment, intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts, intNumOrphanTimePts/intSubSeqTimePts))\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                arrDataSplit = np.zeros((intNumChannels, intSubSeqTimePts, intNumFullSubSeqs), dtype = np.float64)\n",
    "                arrStartEndTimePtsSplit = np.zeros((intNumFullSubSeqs, 2))\n",
    "                \n",
    "                print('     arrDataSplit.shape = {} ({})'.format(arrDataSplit.shape, type(arrDataSplit[0][0][0])))\n",
    "                \n",
    "                if (argTestMode):\n",
    "                    print('     arrDataEDFScaled[0, intStartTimePt:intEndTimePt] = {}'.format(arrDataEDFScaled[0, intStartTimePt:intEndTimePt]))\n",
    "                \n",
    "                lstSegLabels_SlidingWindow = []\n",
    "                lstSegTypes_SlidingWindow  = []\n",
    "                \n",
    "                for intSubSeq in np.arange(intNumFullSubSeqs):\n",
    "                    # Throw an exception if the start of the sliding window extends into the\n",
    "                    # next segment, or the end of the window extends beyond the end point of\n",
    "                    # the entire segment\n",
    "                    if (intWindowStartTimePt > intEndTimePt):\n",
    "                        raise Exception('intWindowStartTimePt ({}) > intEndTimePt ({})'.format(intWindowStartTimePt, intEndTimePt))\n",
    "                    if (intWindowEndTimePt > intNumTimePtsEDF):\n",
    "                        raise Exception('intWindowEndTimePt ({}) > intNumTimePts ({})'.format(intWindowEndTimePt, intNumTimePtsEDF))\n",
    "                    \n",
    "                    # Extract data within the sliding window from arrDataEDFScaled[]\n",
    "                    arrDataWindow = arrDataEDFScaled[:, intWindowStartTimePt:intWindowEndTimePt]\n",
    "                    \n",
    "                    # Fill arrDataSplit[] with data in the sliding window\n",
    "                    arrDataSplit[:, :, intSubSeq] = arrDataWindow\n",
    "                    \n",
    "                    # Record the start and end time points for this subsequence (sliding window)\n",
    "                    arrStartEndTimePtsSplit[intSubSeq, :] = [intWindowStartTimePt, intWindowEndTimePt]\n",
    "                    \n",
    "                    # Create an array with same size as the sliding window with each time\n",
    "                    # point filled with intSegType\n",
    "                    arrSegTypeWindow = arrSegTypeTimePts[intWindowStartTimePt:intWindowEndTimePt]\n",
    "                    \n",
    "                    # Determine whether the sliding window is within the current segment,\n",
    "                    # or whether it has extended into the next segment\n",
    "                    \n",
    "                    # Sliding window has extended into the next segment\n",
    "                    if (intWindowEndTimePt > intEndTimePt):\n",
    "                        strExtendedWindow = '*'\n",
    "                        \n",
    "                        # Make sure that the number of time points in the subwindow is at least 1\n",
    "                        intSubWindowTimePts = math.ceil(argSubWindowFraction * intSubSeqTimePts)\n",
    "                        \n",
    "                        # Find the nearest odd number if the number of time points is even (to\n",
    "                        # ensure that stat.mode() will not raise an exception)\n",
    "                        intSubWindowOddTimePts = ((intSubWindowTimePts // 2) * 2) + 1\n",
    "                        \n",
    "                        # If the nearest odd number is larger than intSubSeqTimePts, trim it down\n",
    "                        # to intSubSeqTimePts\n",
    "                        if (intSubWindowOddTimePts > intSubSeqTimePts):\n",
    "                            intSubWindowOddTimePts = intSubSeqTimePts\n",
    "                            \n",
    "                            # If intSubSeqTimePts happens to be an even number, subtract 1 to\n",
    "                            # make intSubWindowOddTimePts an odd number\n",
    "                            if (utils.fnIsEven(intSubWindowOddTimePts)):\n",
    "                                intSubWindowOddTimePts = intSubWindowOddTimePts - 1\n",
    "                        \n",
    "                        # Create a subwindow within the sliding window (at the MSB end) with\n",
    "                        # each time point filled with intSegType\n",
    "                        arrSegTypeSubWindow = arrSegTypeWindow[-intSubWindowOddTimePts:]\n",
    "                        \n",
    "                        # Get the mode (most common) intSegType within the subwindow\n",
    "                        try:\n",
    "                            intSegTypeMode = stat.mode(arrSegTypeSubWindow)\n",
    "                        except:\n",
    "                            intSegTypeMode = -1\n",
    "                        \n",
    "                        # Assign the segment label and type for the sliding window using the\n",
    "                        # most common label and type in the subwindow\n",
    "                        lstSegLabels_SlidingWindow.append(fnGetSegLabel(intSegTypeMode))\n",
    "                        lstSegTypes_SlidingWindow.append(intSegTypeMode)\n",
    "                        \n",
    "                    # Sliding window is entirely within the current segment\n",
    "                    else:\n",
    "                        strExtendedWindow = ' '\n",
    "                        \n",
    "                        # Simply use the current segment label and type for this window\n",
    "                        lstSegLabels_SlidingWindow.append(strSegLabel)\n",
    "                        lstSegTypes_SlidingWindow.append(intSegType)\n",
    "                        \n",
    "                    # ***TEST MODE:\n",
    "                    if (argTestMode):\n",
    "                        print('       {}intSubSeq = {}: sliding window = {} -> {}, intEndTimePt = {}, arrDataWindow = {}'.format(strExtendedWindow, intSubSeq, intWindowStartTimePt, intWindowEndTimePt, intEndTimePt, arrDataWindow[0, :]))\n",
    "                        print('         arrSegTypeWindow = {}'.format(arrSegTypeWindow))\n",
    "                        \n",
    "                        if (intWindowEndTimePt > intEndTimePt):\n",
    "                            print('         arrSegTypeSubWindow = {} (strSegLabel = {}, intSegType = {})'.format(arrSegTypeSubWindow, lstSegLabels_SlidingWindow[-1], lstSegTypes_SlidingWindow[-1]))\n",
    "                            \n",
    "                        print()\n",
    "                        \n",
    "                    # Move the sliding window forward one step\n",
    "                    intWindowStartTimePt = intWindowStartTimePt + intStepSizeTimePts\n",
    "                    intWindowEndTimePt = intWindowStartTimePt + intSubSeqTimePts\n",
    "                    \n",
    "                print('     arrStartEndTimePtsSplit.shape = {} ({})'.format(arrStartEndTimePtsSplit.shape, type(arrStartEndTimePtsSplit[0][0])))\n",
    "                print('     arrStartEndTimePtsSplit = {} -> {}'.format(arrStartEndTimePtsSplit[0, :], arrStartEndTimePtsSplit[-1:, :]))\n",
    "                \n",
    "                arrStartEndTimesSecSplit = arrStartEndTimePtsSplit / fltSamplingFreq\n",
    "                print('     arrStartEndTimesSecSplit.shape = {} ({})'.format(arrStartEndTimesSecSplit.shape, type(arrStartEndTimesSecSplit[0][0])))\n",
    "                print('     arrStartEndTimesSecSplit = {} -> {}'.format(arrStartEndTimesSecSplit[0, :], arrStartEndTimesSecSplit[-1:, :]))\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                # Loop through each subsequence and save the data and metadata into\n",
    "                # the appropriate data structures\n",
    "\n",
    "                # TODO: To improve performance, instead of looping through each\n",
    "                #       subsequence one by one we may be able to concatenate the\n",
    "                #       whole batch while replicating the other parameters and then\n",
    "                #       append them to the end of each list (done)\n",
    "\n",
    "                # This new method takes about 3 mins to execute for chb01\n",
    "                lstAllBaseFilenames.extend([strFilename] * intNumFullSubSeqs)\n",
    "                #lstAllSegLabels.extend([strSegLabel] * intNumFullSubSeqs)\n",
    "                #lstAllSegTypes.extend([intSegType] * intNumFullSubSeqs)\n",
    "                lstAllSegLabels.extend(lstSegLabels_SlidingWindow)\n",
    "                lstAllSegTypes.extend(lstSegTypes_SlidingWindow)\n",
    "                arrAllData = np.concatenate((arrAllData, arrDataSplit), axis = 2)\n",
    "                lstAllSegDurations.extend([argSubSeqDuration] * intNumFullSubSeqs)   # Record the duration after the split\n",
    "                lstAllSamplingFreqs.extend([argResamplingFreq] * intNumFullSubSeqs)  # Record the resampled frequency\n",
    "                lstAllChannels.extend([lstChannels] * intNumFullSubSeqs)\n",
    "                lstAllSequences.extend([intSequence] * intNumFullSubSeqs)\n",
    "                lstAllSubSequences.extend(list(np.arange(intNumFullSubSeqs)))\n",
    "                \n",
    "                # Concatenate the start/end time points and times (in seconds) for\n",
    "                # each subsequence to the appropriate output data structures\n",
    "                arrAllStartEndTimePts = np.concatenate((arrAllStartEndTimePts, arrStartEndTimePtsSplit), axis = 0)\n",
    "                arrAllStartEndTimesSec = np.concatenate((arrAllStartEndTimesSec, arrStartEndTimesSecSplit), axis = 0)\n",
    "                print('     arrAllStartEndTimePts.shape = {}, arrAllStartEndTimesSec.shape = {}'.format(arrAllStartEndTimePts.shape, arrAllStartEndTimesSec.shape))\n",
    "                print()\n",
    "                \n",
    "                if (argDebug):\n",
    "                    print('     arrAllData.shape = {}'.format(arrAllData.shape))\n",
    "                    print()\n",
    "                    \n",
    "            intNumProcessedFiles = intNumProcessedFiles + 1\n",
    "            \n",
    "    datLoopEnd = utils.fnNow()\n",
    "    print('Loop ended on {}'.format(utils.fnGetDatetime(datLoopEnd)))\n",
    "\n",
    "    datLoopDuration = datLoopEnd - datLoopStart\n",
    "    print('datLoopDuration = {}'.format(datLoopDuration))\n",
    "    \n",
    "    print('intNumProcessedFiles = {}'.format(intNumProcessedFiles))\n",
    "    \n",
    "    # Make sure that the number of files that matched the specified\n",
    "    # extension is the same number of files that we actually processed\n",
    "    if (intNumMatchingFiles != intNumProcessedFiles):\n",
    "        print('WARNING: intNumMatchingFiles != intNumProcessedFiles!')\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    # Resample and round the results to the nearest integer since arrData[channels, time pts]\n",
    "    # is of type int16\n",
    "    if (argResamplingFreq != fltFirstSamplingFreq):\n",
    "        print('Resampling data from {}Hz to {}Hz...'.format(fltFirstSamplingFreq, argResamplingFreq))\n",
    "        print()\n",
    "        \n",
    "        #arrAllDataResampled = signal.resample(arrAllData, intResampledSubSeqTimePts, axis = 1)  # Shape = [channels, subseq time pts, subsequences]\n",
    "        arrAllDataResampled = np.zeros((arrAllData.shape[0], intResampledSubSeqTimePts, arrAllData.shape[2]), dtype = np.float64)  # Shape = [channels, subseq time pts, subsequences]\n",
    "\n",
    "        for intSubSeq in np.arange(arrAllData.shape[2]):\n",
    "            arrAllDataResampled[:, :, intSubSeq] = signal.resample(arrAllData[:, :, intSubSeq], intResampledSubSeqTimePts, axis = 1)\n",
    "            \n",
    "    else:\n",
    "        arrAllDataResampled = arrAllData\n",
    "        \n",
    "    if (argDebug): print('arrAllDataResampled.shape = {} ({})'.format(arrAllDataResampled.shape, type(arrAllDataResampled[0][0])))\n",
    "    \n",
    "    # Process data structures for scaling across training and test sets\n",
    "    lstTestBaseFilenames = []\n",
    "    \n",
    "    for strTestFullFilename in lstMatchingTestFiles:\n",
    "        # Extract the filename from the full path\n",
    "        strPath, strTestFilename = os.path.split(strTestFullFilename)\n",
    "        \n",
    "        lstTestBaseFilenames.append(strTestFilename)\n",
    "        \n",
    "    if (lstTestBaseFilenames):\n",
    "        arrTestDataMin = arrDataMin[:, intNumMatchingFiles:]\n",
    "        arrTestDataMax = arrDataMax[:, intNumMatchingFiles:]\n",
    "        \n",
    "        tupScalingInfo = (lstTestBaseFilenames, arrTestDataMin, arrTestDataMax)\n",
    "    else:\n",
    "        tupScalingInfo = ()\n",
    "    \n",
    "    print('len(lstAllBaseFilenames) = {}'.format(len(lstAllBaseFilenames)))\n",
    "    print('len(lstAllSegLabels) = {}'.format(len(lstAllSegLabels)))\n",
    "    print('len(lstAllSegTypes) = {}'.format(len(lstAllSegTypes)))\n",
    "    print('arrAllData.shape = {} ({}) (features x sequence length x batch size)'.format(arrAllData.shape,  type(arrAllData[0][0][0])))\n",
    "    print('arrAllDataResampled.shape = {} ({}) (features x sequence length x batch size)'.format(arrAllDataResampled.shape,  type(arrAllDataResampled[0][0][0])))\n",
    "    print('len(lstAllSegDurations) = {}'.format(len(lstAllSegDurations)))\n",
    "    print('len(lstAllSamplingFreqs) = {}'.format(len(lstAllSamplingFreqs)))\n",
    "    print('len(lstAllChannels) = {}'.format(len(lstAllChannels)))\n",
    "    print('len(lstAllSequences) = {}'.format(len(lstAllSequences)))\n",
    "    print('len(lstAllSubSequences) = {}'.format(len(lstAllSubSequences)))\n",
    "    print('len(lstSeizureDurations) = {}'.format(len(lstSeizureDurations)))\n",
    "    \n",
    "    # Print the shape of the data structures that store the start/end\n",
    "    # time points and times (in seconds) for each subsequence\n",
    "    print('arrAllStartEndTimePts.shape = {} ({})'.format(arrAllStartEndTimePts.shape, type(arrAllStartEndTimePts[0][0])))\n",
    "    print('arrAllStartEndTimesSec.shape = {} ({})'.format(arrAllStartEndTimesSec.shape, type(arrAllStartEndTimesSec[0][0])))\n",
    "    \n",
    "    if (lstTestBaseFilenames):\n",
    "        # Print data structures for scaling across training and test sets\n",
    "        print('len(lstTestBaseFilenames) = {}'.format(len(lstTestBaseFilenames)))\n",
    "        print('arrTestDataMin.shape = {}, arrTestDataMax.shape = {}'.format(arrTestDataMin.shape, arrTestDataMax.shape))\n",
    "        \n",
    "    print()\n",
    "\n",
    "    print('Size of arrAllData          = {:.2f}Gb'.format(arrAllData.nbytes / (1024**3)))\n",
    "    print('Size of arrAllDataResampled = {:.2f}Gb'.format(arrAllDataResampled.nbytes / (1024**3)))\n",
    "    \n",
    "    if (0):\n",
    "        print('lstAllBaseFilenames = {}'.format(lstAllBaseFilenames))\n",
    "        print('lstAllSegLabels = {}'.format(lstAllSegLabels))\n",
    "        print('lstAllSegTypes = {}'.format(lstAllSegTypes))\n",
    "        print('arrAllData = {}'.format(arrAllData))\n",
    "        print('arrAllDataResampled = {}'.format(arrAllDataResampled))\n",
    "        print('lstAllSegDurations = {}'.format(lstAllSegDurations))\n",
    "        print('lstAllSamplingFreqs = {}'.format(lstAllSamplingFreqs))\n",
    "        print('lstAllChannels = {}'.format(lstAllChannels))\n",
    "        print('lstAllSequences = {}'.format(lstAllSequences))\n",
    "        print('lstAllSubSequences = {}'.format(lstAllSubSequences))\n",
    "        print('lstSeizureDurations = {}'.format(lstSeizureDurations))\n",
    "        print('arrAllStartEndTimePts = {}'.format(arrAllStartEndTimePts))\n",
    "        print('arrAllStartEndTimesSec = {}'.format(arrAllStartEndTimesSec))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    return lstAllBaseFilenames, lstAllSegLabels, lstAllSegTypes, arrAllDataResampled, lstAllSegDurations, lstAllSamplingFreqs, lstAllChannels, lstAllSequences, lstAllSubSequences, lstSeizureDurations, arrAllStartEndTimesSec, tupScalingInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one or more EEG segments from the CHB-MIT data set from\n",
    "# files (.edf) based on which files are specified in argCSVPath\n",
    "\n",
    "# The units of argResamplingFreq is in Hz and argSubSeqDuration is in\n",
    "# seconds\n",
    "\n",
    "# NOTE: Subjects under 3 yrs old, i.e. chb06 (1.5 yrs old) and chb12 (2 yrs old),\n",
    "# should be excluded, according to Jeffrey, since the base frequency of their EEGs\n",
    "# have yet reached the adult level of 8.5Hz\n",
    "\n",
    "def fnReadCHBMITEDFFiles(argCSVPath, argResamplingFreq = -1, argSubSeqDuration = -1, argScalingParams = (), argAnnoSuffix = 'seizures', argDebug = False):\n",
    "    lstMatchingFiles = fnReadDataFileListCSV(argCSVPath)\n",
    "    \n",
    "    intNumMatchingFiles = len(lstMatchingFiles)  # Number of matching files\n",
    "    if (argDebug):\n",
    "        print('intNumMatchingFiles = {}'.format(intNumMatchingFiles))\n",
    "        print()\n",
    "    \n",
    "    # Check whether there are mismatched channels in all EDF files\n",
    "    fnMatchEDFChannels(lstMatchingFiles)\n",
    "    \n",
    "    # Read the first .edf file to extract parameters that are global\n",
    "    # across the data set\n",
    "    \n",
    "    # NOTE: For EDF files, it is possible that for each segment, each\n",
    "    #       channel can have different:\n",
    "    #         (1) number of time points/segment lengths, and\n",
    "    #         (2) sampling frequencies\n",
    "    #\n",
    "    #       And at a patient level, it is also possible that different\n",
    "    #       segments have different:\n",
    "    #         (4) number of channels\n",
    "    #         (5) number of time points\n",
    "    #         (6) sampling frequencies\n",
    "    #\n",
    "    #       For the CHB-MIT data set, only (5) is true, so we will need\n",
    "    #       to handle different segment lengths as we read in each EDF\n",
    "    #       file, and assume that the other parameters are global. This\n",
    "    #       will simplify the code somewhat without having to handle all\n",
    "    #       these parameters as variables for each EDF file\n",
    "    #\n",
    "    #       ***TODO***:\n",
    "    #       HOWEVER, at a data set level, the number of channels across\n",
    "    #       different patients can be different. If we want to train a\n",
    "    #       generalized model, we will have to find the minimum montage\n",
    "    #       that is common across a set of patients. We currently do not\n",
    "    #       have the code to handle this situation\n",
    "    \n",
    "    strSegLabel, arrData, fltSegDuration, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePts = fnReadEDFUsingPyEDFLib(lstMatchingFiles[0], argDebug = True)\n",
    "    \n",
    "    # If argResamplingFreq = -1 (default) or argResamplingFreq > intSamplingFreq,\n",
    "    # use the *first* sampling frequency (upsampling is not allowed for now)\n",
    "    if ((argResamplingFreq == -1) or (argResamplingFreq > fltSamplingFreq)):\n",
    "        argResamplingFreq = fltSamplingFreq        \n",
    "    print('argResamplingFreq = {}Hz'.format(argResamplingFreq))\n",
    "    \n",
    "    # If argSubSeqDuration = -1 (default) or argSubSeqDuration > intSegDuration,\n",
    "    # default back to the *first* segment duration\n",
    "    if ((argSubSeqDuration == -1) or (argSubSeqDuration > fltSegDuration)):\n",
    "        argSubSeqDuration = fltSegDuration  # Do not break segment into subsequences\n",
    "    print('argSubSeqDuration = {}s'.format(argSubSeqDuration))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Calculate the number of time points in each segment after the resampling\n",
    "    intResampledTimePts = int(round((argResamplingFreq / fltSamplingFreq) * intNumTimePts))\n",
    "    print('intResampledTimePts = {}'.format(intResampledTimePts))\n",
    "\n",
    "    # Calculate the number of time points in each segment after splitting up the segment\n",
    "    # into shorter sequences\n",
    "    intSubSeqTimePts = int(round((argSubSeqDuration / fltSegDuration) * intResampledTimePts))\n",
    "    print('intSubSeqTimePts = {}'.format(intSubSeqTimePts))\n",
    "        \n",
    "    # Initialize data structures to store data for the entire data set\n",
    "    lstAllBaseFilenames = []  # List of segment filenames\n",
    "    lstAllSegLabels = []      # List of segment labels\n",
    "    lstAllSegTypes = []       # List of segment types (preictal = 1 or interictal = 2)\n",
    "    \n",
    "    # NOTE: arrAllData[] can no longer be initialized prior to reading all the\n",
    "    #       segments, as each segment are now allowed to have a different length\n",
    "    #       (intNumTimePts), so each segment may be split into a different number\n",
    "    #       of subsequences (intNumFullSubSeqs). Therefore, we can no longer\n",
    "    #       calculate the total number of subsequences (intTotalBatchSize) based\n",
    "    #       on the number of sequences (intNumMatchingFiles) and the number of\n",
    "    #       subsequences per file (intNumSubSeqs)\n",
    "    #\n",
    "    #       Instead, we will create arrAllData[] with a fixed number of channels\n",
    "    #       and subsequence time points (both of which are expected to be\n",
    "    #       consistent across the data set), and a 3rd dimension with zero size\n",
    "    #       that we will append the subsequences to as we loop through each file\n",
    "    #\n",
    "    #       intTotalBatchSize = intNumMatchingFiles * intNumSubSeqs  # Total number of sequences\n",
    "    \n",
    "    arrAllData = np.zeros((intNumChannels, intSubSeqTimePts, 0), dtype = np.float64)\n",
    "    if (argDebug): print('arrAllData.shape = {}'.format(arrAllData.shape))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    lstAllSegDurations = []   # List of segment durations (in seconds)\n",
    "    lstAllSamplingFreqs = []  # List of sampling frequencies (in Hz)\n",
    "    lstAllChannels = []       # List of lists (of channel names)\n",
    "    lstAllSequences = []      # List of sequence indices\n",
    "    lstAllSubSequences = []   # List of subsequence indices (if one sequence is broken up into subsequences)\n",
    "    \n",
    "    # List of start/end time points and times (in seconds) for each subsequence\n",
    "    arrAllStartEndTimePts  = np.zeros((0, 2))\n",
    "    arrAllStartEndTimesSec = np.zeros((0, 2), dtype = np.float64)\n",
    "    \n",
    "    lstSeizureDurations = []  # List of seizure durations (in seconds) (not broken into subsequences)\n",
    "    \n",
    "    datLoopStart = utils.fnNow()\n",
    "    print('Loop started on {}'.format(utils.fnGetDatetime(datLoopStart)))\n",
    "    print()\n",
    "    \n",
    "    intNumProcessedFiles = 0\n",
    "    fltFirstSamplingFreq = fltSamplingFreq  # Remember the sampling frequency of the first file\n",
    "    lstFirstChannels = lstChannels          # Remember the list of channels of the first file\n",
    "    \n",
    "    print('fltFirstSamplingFreq = {}Hz'.format(fltFirstSamplingFreq))\n",
    "    print('lstFirstChannels = {}'.format(lstFirstChannels))\n",
    "    print()\n",
    "    \n",
    "    # SCALING\n",
    "    if (argScalingParams):\n",
    "        intScalingMode  = argScalingParams[0]\n",
    "        tupScaledMinMax = argScalingParams[1]\n",
    "        print('Scaling data using: intScalingMode = {}, tupScaledMinMax = {}'.format(intScalingMode, tupScaledMinMax))\n",
    "        print()\n",
    "        \n",
    "        # TODO: Currently we are reading in the same data set twice, so this is not speed\n",
    "        #       efficient. Maybe we should combine these two loops into one    \n",
    "        # SCALING: Collect the statistics of the specified EDF files\n",
    "        arrDataSetMin, arrDataSetMax, arrDataSetMean = fnGetCHBMITStats(lstMatchingFiles, argDebug = False)\n",
    "        \n",
    "        # Construct arrDataMin and arrDataMax based on the scaling mode\n",
    "        arrDataMin, arrDataMax = fnGenMinMaxArrays(intScalingMode, arrDataSetMin, arrDataSetMax, argDebug = False)\n",
    "        \n",
    "    else:\n",
    "        print('Data scaling is not performed')\n",
    "        print()\n",
    "        \n",
    "    # Loop through each file in the target directory                             \n",
    "    for intFullFilenameIdx, strFullFilename in enumerate(lstMatchingFiles):  # SCALING\n",
    "        # Process only .edf files\n",
    "        if strFullFilename.endswith('.edf'):\n",
    "            print('Processing {}...'.format(strFullFilename))\n",
    "            \n",
    "            # Extract the filename from the full path\n",
    "            strPath, strFilename = os.path.split(strFullFilename)\n",
    "            \n",
    "            # Read the .edf file\n",
    "            strSegLabel, arrDataEDF, fltSegDurationEDF, fltSamplingFreq, lstChannels, intSequence, intNumChannels, intNumTimePtsEDF = fnReadEDFUsingPyEDFLib(strFullFilename, argDebug = False)\n",
    "            print('  fltSegDurationEDF = {}s, fltSampingFreq = {}Hz'.format(fltSegDurationEDF, fltSamplingFreq))\n",
    "            print()\n",
    "            \n",
    "            if (argScalingParams):\n",
    "                # SCALING: Construct arrDataMinMax (C x 2) from arrDataMin and arrDataMax\n",
    "                #          (C x N)\n",
    "                # SCALING (normalize, filter, smoothing(?), augment (later))\n",
    "                arrDataMinMax = np.concatenate((arrDataMin[:, intFullFilenameIdx][:, np.newaxis], arrDataMax[:, intFullFilenameIdx][:, np.newaxis]), axis = 1)\n",
    "                arrDataEDFScaled = utils.fnMinMaxScaler(arrDataEDF, tupScaledMinMax, arrDataMinMax, argDebug = False)\n",
    "            else:\n",
    "                arrDataEDFScaled = arrDataEDF\n",
    "                \n",
    "            # Consistency check for sampling rate and channel labels\n",
    "            if (fltSamplingFreq != fltFirstSamplingFreq):\n",
    "                raise Exception('Sampling frequency not consistent across the data segments!')\n",
    "                \n",
    "            if (lstChannels != lstFirstChannels):\n",
    "                raise Exception('Channels not consistent across the data segments!')\n",
    "            \n",
    "            # Check to see if an annotation file (.seizures) exists. If so, set strSegLabel\n",
    "            # and determine the seizure start/end times\n",
    "            \n",
    "            # TODO: Change argAnnoSuffix to argReadAnnoTxt (boolean) to call fnReadCHBMITAnno()\n",
    "            #       to read binary 'seizures' files when false, and call fnReadCHBMITAnnoTxt()\n",
    "            #       to read ASCII 'annotation.txt' files when true\n",
    "            #blnAnnoFound, lstStartEndTimePts = fnReadCHBMITAnno(strFullFilename, argAnnoSuffix)\n",
    "            blnAnnoFound, lstStartEndTimePts = fnReadCHBMITAnnoTxt(strFullFilename, argAnnoSuffix, fltSamplingFreq)\n",
    "            \n",
    "            # SCALING\n",
    "            # Break the segment up based on their respective segment types\n",
    "            lstSegLabels, lstSegTypes, lstStartEndTimePts, lstStartEndTimeSecs, lstSegDurations, lstNumTimePts, lstDataSegs = fnBreakCHBMITSegment(arrDataEDFScaled, lstStartEndTimePts, fltSamplingFreq, argDebug = True)\n",
    "                        \n",
    "            # Loop through each segment to generate the appropriate subsequences \n",
    "            for intSegIdx, tupSeg in enumerate(zip(lstSegLabels, lstSegTypes, lstStartEndTimePts, lstStartEndTimeSecs, lstSegDurations, lstNumTimePts, lstDataSegs)):\n",
    "                strSegLabel, intSegType, tupStartEndTimePt, tupStartEndTimeSec, fltSegDuration, intNumTimePts, arrDataSeg = [*tupSeg]\n",
    "                \n",
    "                # Extract the start and end time points of each segment\n",
    "                intStartTimePt, intEndTimePt   = tupStartEndTimePt\n",
    "                fltStartTimeSec, fltEndTimeSec = tupStartEndTimeSec\n",
    "                \n",
    "                if (fnIsSegState('ictal', intSegType)):\n",
    "                    lstSeizureDurations.append((strFilename, fltSegDuration))\n",
    "                    print('  => SEGMENT ({}) = ***{}***'.format(intSegIdx + 1, strSegLabel.upper()))\n",
    "                else:\n",
    "                    print('  => SEGMENT ({}) = {}'.format(intSegIdx + 1, strSegLabel.upper()))\n",
    "                    \n",
    "                print('    {:.6f}s ({}) -> {:.6f}s ({}), duration = {:.6f}s ({}), arrDataSeg.shape = {}'.format(fltStartTimeSec, intStartTimePt, fltEndTimeSec, intEndTimePt, fltSegDuration, intNumTimePts, arrDataSeg.shape))\n",
    "                \n",
    "                # Terminate the function with an error if argSubSeqDuration is longer than\n",
    "                # fltSegDuration for the current segment\n",
    "                if (argSubSeqDuration > fltSegDuration):\n",
    "                    raise Exception('argSubSeqDuration ({}s) > fltSegDuration ({}s)'.format(argSubSeqDuration, fltSegDuration))\n",
    "                    \n",
    "                # Calculate the number of time points in each segment after the resampling\n",
    "                intResampledTimePts = int(round((argResamplingFreq / fltSamplingFreq) * intNumTimePts))\n",
    "                print('     intResampledTimePts = {}'.format(intResampledTimePts))\n",
    "\n",
    "                # Calculate the number of time points in each segment after splitting up the segment\n",
    "                # into shorter sequences\n",
    "                intSubSeqTimePts = int(round((argSubSeqDuration / fltSegDuration) * intResampledTimePts))\n",
    "                print('     intSubSeqTimePts = {}'.format(intSubSeqTimePts))\n",
    "                \n",
    "                # Analyze the number of subsequences to break down from the main segment, and\n",
    "                # whether the time points can be equally divided among all the subsequences\n",
    "                intNumSubSeqs = math.ceil(intResampledTimePts / intSubSeqTimePts)  # Total number of subsequences required\n",
    "                intNumFullSubSeqs = intResampledTimePts // intSubSeqTimePts        # Number of completely filled subsequences\n",
    "                intNumOrphanTimePts = intResampledTimePts % intSubSeqTimePts       # Number of orphan time points\n",
    "                \n",
    "                if (argDebug):\n",
    "                    print('     intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts = {} / {} / {} ({:.2f}%)'.format(intNumSubSeqs, intNumFullSubSeqs, intNumOrphanTimePts, intNumOrphanTimePts/intSubSeqTimePts))\n",
    "                    print()\n",
    "\n",
    "                # If the number of subsequence time points specified results in the\n",
    "                # last subsequence not being completely filled up, give a warning message\n",
    "                if (intNumOrphanTimePts > 0):\n",
    "                    print('     WARNING: Time points cannot be divided into complete subsequences')\n",
    "\n",
    "                if (intNumFullSubSeqs > 1):\n",
    "                    print('     Splitting each segment into {} subsequences based on intSubSeqTimePts = {}'.format(intNumFullSubSeqs, intSubSeqTimePts))\n",
    "                    \n",
    "                print()\n",
    "\n",
    "                # Resample and round the results to the nearest integer since arrData[] is of type int16\n",
    "                if (argResamplingFreq != fltFirstSamplingFreq):\n",
    "                    arrDataResampled = signal.resample(arrDataSeg, intResampledTimePts, axis = 1)\n",
    "                else:\n",
    "                    arrDataResampled = arrDataSeg\n",
    "                    \n",
    "                if (argDebug): print('     arrDataResampled.shape = {} ({})'.format(arrDataResampled.shape, type(arrDataResampled[0][0])))\n",
    "\n",
    "                # Truncate arrData[channels, time pts] to remove any orphan time points, if any\n",
    "                intNumUsableTimePts = intSubSeqTimePts * intNumFullSubSeqs\n",
    "                \n",
    "                # If interictal segment, trim from the beginning. If ictal, trim from the end.\n",
    "                # This is because the end of an interictal segment might be preictal if the\n",
    "                # next segment is ictal, and the beginning of an ictal segment is more crucial\n",
    "                # for training than the end of such a segment\n",
    "                if (fnIsSegState('ictal', intSegType)):\n",
    "                    intTrimStart = 0\n",
    "                    intTrimEnd   = intNumUsableTimePts\n",
    "                else:\n",
    "                    intTrimStart = intResampledTimePts - intNumUsableTimePts\n",
    "                    intTrimEnd   = intResampledTimePts\n",
    "                    \n",
    "                arrDataTruncated = arrDataResampled[:, intTrimStart:intTrimEnd]\n",
    "                if (argDebug): print('     intNumUsableTimePts = {}, intTrimStart/End = [{}:{}], arrDataTrauncated.shape = {} ({})'.format(intNumUsableTimePts, intTrimStart, intTrimEnd, arrDataTruncated.shape, type(arrDataTruncated [0][0])))\n",
    "\n",
    "                # Reshape arrDataTruncated[channels, time pts] into arrDataSplit[channels, subseq time pts, subsequences]\n",
    "                # where the subsequences are split along the 3rd dimension\n",
    "                arrDataSplit = arrDataTruncated.reshape(intNumChannels, -1, intSubSeqTimePts)\n",
    "                arrDataSplit = np.swapaxes(arrDataSplit, 1, 2)\n",
    "                if (argDebug): print('     arrDataSplit.shape = {} ({})'.format(arrDataSplit.shape, type(arrDataSplit[0][0][0])))\n",
    "                \n",
    "                # Calculate the actual start/end time points and times (in seconds) for each\n",
    "                # trimmed segment (interictal or ictal)\n",
    "                intTrimStartTimePt  = intTrimStart + intStartTimePt\n",
    "                intTrimEndTimePt    = intTrimEnd + intStartTimePt\n",
    "                fltTrimStartTimeSec = intTrimStartTimePt / argResamplingFreq\n",
    "                fltTrimEndTimeSec   = intTrimEndTimePt / argResamplingFreq\n",
    "                print('     intTrimStartTimePt = {:.6f}s ({}), intTrimEndTImePt = {:.6f}s ({})'.format(fltTrimStartTimeSec, intTrimStartTimePt, fltTrimEndTimeSec, intTrimEndTimePt))\n",
    "                \n",
    "                # Calculate the start/end time points and times (in seconds) for each subsequence\n",
    "                arrStartEndTimePtsSplit = np.concatenate((np.arange(intTrimStartTimePt, intTrimEndTimePt, intSubSeqTimePts)[:, np.newaxis], \n",
    "                                                  np.arange(intTrimStartTimePt + intSubSeqTimePts, intTrimEndTimePt + 1, intSubSeqTimePts)[:, np.newaxis]), axis = 1)\n",
    "                print('     arrStartEndTimePtsSplit.shape = {} ({})'.format(arrStartEndTimePtsSplit.shape, type(arrStartEndTimePtsSplit[0][0])))\n",
    "                print('     arrStartEndTimePtsSplit = {} -> {}'.format(arrStartEndTimePtsSplit[0, :], arrStartEndTimePtsSplit[-1:, :]))\n",
    "\n",
    "                arrStartEndTimesSecSplit = arrStartEndTimePtsSplit / argResamplingFreq\n",
    "                print('     arrStartEndTimesSecSplit.shape = {} ({})'.format(arrStartEndTimesSecSplit.shape, type(arrStartEndTimesSecSplit[0][0])))\n",
    "                print('     arrStartEndTimesSecSplit = {} -> {}'.format(arrStartEndTimesSecSplit[0, :], arrStartEndTimesSecSplit[-1:, :]))\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                # Loop through each subsequence and save the data and metadata into\n",
    "                # the appropriate data structures\n",
    "\n",
    "                # TODO: To improve performance, instead of looping through each\n",
    "                #       subsequence one by one we may be able to concatenate the\n",
    "                #       whole batch while replicating the other parameters and then\n",
    "                #       append them to the end of each list (done)\n",
    "\n",
    "                # This new method takes about 3 mins to execute for chb01\n",
    "                lstAllBaseFilenames.extend([strFilename] * intNumFullSubSeqs)\n",
    "                lstAllSegLabels.extend([strSegLabel] * intNumFullSubSeqs)\n",
    "                lstAllSegTypes.extend([intSegType] * intNumFullSubSeqs)\n",
    "                arrAllData = np.concatenate((arrAllData, arrDataSplit), axis = 2)\n",
    "                lstAllSegDurations.extend([argSubSeqDuration] * intNumFullSubSeqs)   # Record the duration after the split\n",
    "                lstAllSamplingFreqs.extend([argResamplingFreq] * intNumFullSubSeqs)  # Record the resampled frequency\n",
    "                lstAllChannels.extend([lstChannels] * intNumFullSubSeqs)\n",
    "                lstAllSequences.extend([intSequence] * intNumFullSubSeqs)\n",
    "                lstAllSubSequences.extend(list(np.arange(intNumFullSubSeqs)))\n",
    "                \n",
    "                # Concatenate the start/end time points and times (in seconds) for\n",
    "                # each subsequence to the appropriate output data structures\n",
    "                arrAllStartEndTimePts = np.concatenate((arrAllStartEndTimePts, arrStartEndTimePtsSplit), axis = 0)\n",
    "                arrAllStartEndTimesSec = np.concatenate((arrAllStartEndTimesSec, arrStartEndTimesSecSplit), axis = 0)\n",
    "                print('     arrAllStartEndTimePts.shape = {}, arrAllStartEndTimesSec.shape = {}'.format(arrAllStartEndTimePts.shape, arrAllStartEndTimesSec.shape))\n",
    "                print()\n",
    "                \n",
    "                if (argDebug):\n",
    "                    print('     arrAllData.shape = {}'.format(arrAllData.shape))\n",
    "                    print()\n",
    "                    \n",
    "            intNumProcessedFiles = intNumProcessedFiles + 1\n",
    "            \n",
    "    datLoopEnd = utils.fnNow()\n",
    "    print('Loop ended on {}'.format(utils.fnGetDatetime(datLoopEnd)))\n",
    "\n",
    "    datLoopDuration = datLoopEnd - datLoopStart\n",
    "    print('datLoopDuration = {}'.format(datLoopDuration))\n",
    "    \n",
    "    print('intNumProcessedFiles = {}'.format(intNumProcessedFiles))\n",
    "    \n",
    "    # Make sure that the number of files that matched the specified\n",
    "    # extension is the same number of files that we actually processed\n",
    "    if (intNumMatchingFiles != intNumProcessedFiles):\n",
    "        print('WARNING: intNumMatchingFiles != intNumProcessedFiles!')\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    print('len(lstAllBaseFilenames) = {}'.format(len(lstAllBaseFilenames)))\n",
    "    print('len(lstAllSegLabels) = {}'.format(len(lstAllSegLabels)))\n",
    "    print('len(lstAllSegTypes) = {}'.format(len(lstAllSegTypes)))\n",
    "    print('arrAllData.shape = {} ({}) (features x sequence length x batch size)'.format(arrAllData.shape,  type(arrAllData[0][0][0])))\n",
    "    print('len(lstAllSegDurations) = {}'.format(len(lstAllSegDurations)))\n",
    "    print('len(lstAllSamplingFreqs) = {}'.format(len(lstAllSamplingFreqs)))\n",
    "    print('len(lstAllChannels) = {}'.format(len(lstAllChannels)))\n",
    "    print('len(lstAllSequences) = {}'.format(len(lstAllSequences)))\n",
    "    print('len(lstAllSubSequences) = {}'.format(len(lstAllSubSequences)))\n",
    "    print('len(lstSeizureDurations) = {}'.format(len(lstSeizureDurations)))\n",
    "    \n",
    "    # Print the shape of the data structures that store the start/end\n",
    "    # time points and times (in seconds) for each subsequence\n",
    "    print('arrAllStartEndTimePts.shape = {} ({})'.format(arrAllStartEndTimePts.shape, type(arrAllStartEndTimePts[0][0])))\n",
    "    print('arrAllStartEndTimesSec.shape = {} ({})'.format(arrAllStartEndTimesSec.shape, type(arrAllStartEndTimesSec[0][0])))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    if (0):\n",
    "        print('lstAllBaseFilenames = {}'.format(lstAllBaseFilenames))\n",
    "        print('lstAllSegLabels = {}'.format(lstAllSegLabels))\n",
    "        print('lstAllSegTypes = {}'.format(lstAllSegTypes))\n",
    "        print('arrAllData = {}'.format(arrAllData))\n",
    "        print('lstAllSegDurations = {}'.format(lstAllSegDurations))\n",
    "        print('lstAllSamplingFreqs = {}'.format(lstAllSamplingFreqs))\n",
    "        print('lstAllChannels = {}'.format(lstAllChannels))\n",
    "        print('lstAllSequences = {}'.format(lstAllSequences))\n",
    "        print('lstSeizureDurations = {}'.format(lstSeizureDurations))\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return lstAllBaseFilenames, lstAllSegLabels, lstAllSegTypes, arrAllData, lstAllSegDurations, lstAllSamplingFreqs, lstAllChannels, lstAllSequences, lstAllSubSequences, lstSeizureDurations, arrAllStartEndTimesSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnWriteTestAnnoFiles(argEDFFilenames, argTestResults, argStartEndTimesSec, argFalsePositivesMask, argFalseNegativeMask, argParentPath, argAnnoSuffix = 'annotation.txt', argDebug = False):\n",
    "    arrEDFFilenames_Incorrect = np.unique(\n",
    "        argEDFFilenames[argTestResults[:, 1] != argTestResults[:, 2]], return_index = False, return_inverse = False, return_counts = False, axis = 0)\n",
    "    \n",
    "    utils.fnOSMakeDir(argParentPath)\n",
    "    \n",
    "    for strEDFFilename in arrEDFFilenames_Incorrect:\n",
    "        if (argDebug): print('strEDFFilename = {}:'.format(strEDFFilename))\n",
    "        \n",
    "        arrEDFFilenameMask = argEDFFilenames == strEDFFilename\n",
    "        \n",
    "        strAnnoFullFilename = argParentPath + strEDFFilename + '.' + argAnnoSuffix\n",
    "        print('strAnnoFullFilename = {}'.format(strAnnoFullFilename))\n",
    "        \n",
    "        # Open the annotation file for writing\n",
    "        with open(strAnnoFullFilename, 'w') as fhAnnoFile:\n",
    "            fhAnnoFile.write('Onset,Duration,Annotation\\n')\n",
    "            #print('Onset,Duration,Annotation')\n",
    "            \n",
    "            strAnnotation = 'Ii->Ic'\n",
    "            for fltStartTime, fltEndTime in argStartEndTimesSec[np.logical_and(arrEDFFilenameMask, argFalsePositivesMask), :]:\n",
    "                fhAnnoFile.write('+{:.7f},{:.6f},{}\\n'.format(fltStartTime, fltEndTime - fltStartTime, strAnnotation))\n",
    "                #print('+{:.7f},{:.6f},{}'.format(fltStartTime, fltEndTime - fltStartTime, strAnnotation))\n",
    "                \n",
    "            strAnnotation = 'Ic->Ii'\n",
    "            for fltStartTime, fltEndTime in argStartEndTimesSec[np.logical_and(arrEDFFilenameMask, argFalseNegativeMask), :]:\n",
    "                fhAnnoFile.write('+{:.7f},{:.6f},{}\\n'.format(fltStartTime, fltEndTime - fltStartTime, strAnnotation))\n",
    "                #print('+{:.7f},{:.6f},{}'.format(fltStartTime, fltEndTime - fltStartTime, strAnnotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to export Kaggle prediction EEG data to a CSV file\n",
    "#\n",
    "# (1) Generate first column of timestamps based on sampling frequency\n",
    "#     Use lstAllSegDurations[0] to get the final segment duration, and\n",
    "#     lstAllSamplingFreqs[0] for the final sampling frequency\n",
    "#\n",
    "# (2) Convert raw data from row- to column-based\n",
    "\n",
    "# NOTE: Assumes argData is a single, multi-channel segment with dimensions m x n,\n",
    "#       where m is the number of channels, and n is the number of time points\n",
    "\n",
    "def fnExportEEG2CSV(argFilename, argSegLabel, argData, argSegDuration, argSamplingFreq, argChannels, argSequence, argSubSequence, argCSVPath = './', argDebug = False):\n",
    "    fltResamplingFreq = argSamplingFreq\n",
    "    fltSubSeqDuration = argSegDuration\n",
    "    \n",
    "    # Extract the filename and file extension\n",
    "    strBasename, strFileExt = os.path.splitext(argFilename)\n",
    "\n",
    "    strCSVFilename = '{}-{}_{:.2f}Hz_{}s.csv'.format(strBasename, argSubSequence, argSamplingFreq, argSegDuration)\n",
    "    strCSVFullFilename = os.path.join(argCSVPath, strCSVFilename)\n",
    "\n",
    "    print('Saving CSV file to {}...'.format(strCSVFullFilename))\n",
    "    \n",
    "    if (argDebug):\n",
    "        print('fltResamplingFreq = {}, fltSubSeqDuration = {}'.format(fltResamplingFreq, fltSubSeqDuration))\n",
    "        print('argData.shape = {}'.format(argData.shape))\n",
    "\n",
    "    arrSegmentData = argData\n",
    "    if (argDebug):\n",
    "        print('arrSegmentData.shape = {}'.format(arrSegmentData.shape))\n",
    "        print()\n",
    "        \n",
    "    fltTimeDelta = 1/fltResamplingFreq * 1000  # Unit = ms\n",
    "    intNumChannels, intNumTimePts = arrSegmentData.shape\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(strCSVFullFilename, 'w') as fhCSVFile:\n",
    "\n",
    "        if (argDebug):\n",
    "            print('% OpenBCI Raw EEG Data Format (adapted by Caleb Chan)')\n",
    "            print('%')\n",
    "            print('% Segment label = {}'.format(argSegLabel))\n",
    "            print('% Channels = {}'.format(argChannels))\n",
    "            print('% Sequence = {}'.format(argSequence))\n",
    "            print('% SubSequence = {}'.format(argSubSequence))\n",
    "            print('%')\n",
    "            print('% Sample Rate = {:.2f} Hz'.format(fltResamplingFreq))\n",
    "            print('% SubSequence Duration = {}s'.format(fltSubSeqDuration))\n",
    "            print('%')\n",
    "            print('% First Column = Time (ms)')\n",
    "            print('% Other Columns = EEG data in microvolts (uV), with one channel per column')\n",
    "\n",
    "        fhCSVFile.write('% OpenBCI Raw EEG Data Format (adapted by Caleb Chan)\\n')\n",
    "        fhCSVFile.write('%\\n')\n",
    "        fhCSVFile.write('% Segment label = {}\\n'.format(argSegLabel))\n",
    "        fhCSVFile.write('% Channels = {}\\n'.format(argChannels))\n",
    "        fhCSVFile.write('% Sequence = {}\\n'.format(argSequence))\n",
    "        fhCSVFile.write('% SubSequence = {}\\n'.format(argSubSequence))\n",
    "        fhCSVFile.write('%\\n')\n",
    "        fhCSVFile.write('% Sample Rate = {:.2f} Hz\\n'.format(fltResamplingFreq))\n",
    "        fhCSVFile.write('% SubSequence Duration = {}s\\n'.format(fltSubSeqDuration))\n",
    "        fhCSVFile.write('%\\n')\n",
    "        fhCSVFile.write('% First Column = Time (ms)\\n')\n",
    "        fhCSVFile.write('% Other Columns = EEG data in microvolts (uV) with one channel per column\\n')\n",
    "\n",
    "        for intTimeStep in np.arange(intNumTimePts):\n",
    "            fltTimeInMS = intTimeStep * fltTimeDelta\n",
    "\n",
    "            lstDataRow = list(arrSegmentData[:, intTimeStep])\n",
    "            strDataRowFormat = len(lstDataRow) * '{:.2f}, '\n",
    "            strDataRow = strDataRowFormat.format(*lstDataRow).rstrip(', ')\n",
    "\n",
    "            if (argDebug):\n",
    "                print('{}, {:.1f}, {}'.format(intTimeStep, fltTimeInMS, strDataRow))\n",
    "\n",
    "            fhCSVFile.write('{:.1f}, {}\\n'.format(fltTimeInMS, strDataRow))\n",
    "\n",
    "            if (argDebug):\n",
    "                if (intTimeStep == 19): break\n",
    "\n",
    "    fhCSVFile.close()  # Close the CSV file (optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
